[
    {
        "document_id": "Lecture02_Comb.pdf",
        "text": "1Chapter 2Combinational logic\n© Copyright 2004, Gaetano Borriello and Randy H. Katz2Overview: Combinational logicnBasic logicqBoolean algebra, proofs by re-writing, proofs by perfect inductionqlogic functions, truth tables, and switchesqNOT, AND, OR, NAND, NOR, XOR, . . ., minimal setnLogic realizationqtwo-level logic and canonical formsqincompletely specified functionsnSimplificationquniting theoremqgrouping of terms in Boolean functionsnAlternate representations of Boolean functionsqcubesqKarnaugh maps3XY0000000000111111110100001111000011111000110011001100111101010101010101010X andYXYX orYnotYnotX1XYF\nX xorYX norYnot(X orY)X = YX nandYnot(X andY)Possible logic functions of two variablesnThere are 16 possible functions of 2 input variables:qin general, there are 2**(2**n) functions of n inputsF0F3F6F9F12F15F14Cost of different logic functionsnDifferent functions are easier or harder to implementqeach has a cost associated with the number of switches neededq0 (F0) and 1 (F15): require 0 switches, directly connect output to low/highqX (F3) and Y (F5): require 0 switches, output is one of inputsqX’ (F12) and Y’ (F10): require 2 switches for \"inverter\" or NOT-gateqX nor Y (F8) and X nand Y (F14): require 4 switchesqX or Y (F7) and X and Y (F1): require 6 switchesqX = Y (F9) and X ÅY (F6): require 16 switchesqthus, because NOT, NOR, and NAND are the cheapest they are the functions we implement the most in practice5XYX nand Y001110XYX nor Y001110X nandYºnot(  (notX) nor(notY)  )X norYºnot( (notX) nand(notY) )Minimal set of functionsnCan we implement all logic functions from NOT, NOR, and NAND?qFor example, implementing          X and Yis the same as implementing   not (X nand Y)nIn fact, we can do it with only NOR or only NANDqNOT is just a NAND or a NOR with both inputs tied together\nqNAND and NOR are \"duals\",that is, its easy to implement one using the other6An algebraic structurenAn algebraic structure consists ofqa set of elements Bqbinary operations { + , • }qand a unary operation { ’ }qsuch that the following axioms hold:1. the set B contains at least two elements: a, b2. closure:a + b is in Ba • b is in B3. commutativity:a + b = b + aa • b = b • a4. associativity:a + (b + c) = (a + b) + ca • (b • c) = (a • b) • c5. identity:a + 0 = aa • 1 = a6. distributivity:a + (b • c) = (a + b) • (a + c)a • (b + c) = (a • b) + (a • c)7. complementarity:a + a’ = 1a • a’ = 0Identity (element) 항등원7Boolean algebranBoolean algebraqB = {0, 1}qvariablesq+ is logical OR, • is logical ANDq’ is logical NOTnAll algebraic axioms hold8X, Y are Boolean algebra variablesXYX •Y000010100111XYX’Y’X •YX’ •Y’( X •Y ) + ( X’ •Y’ )0011011011000010010001100101( X •Y ) + ( X’ •Y’ )     ºX =YXYX’X’ • Y0010011110001100Boolean expression that is true when the variables X and Y have the same valueand false, otherwiseLogic functions and Boolean algebranAny logic function that can be expressed as a truth table can be written as an expression in Boolean algebra using the operators: ’, +, and •9nidentity1.   X + 0 = X1D.   X • 1 = Xnnull2.   X + 1 = 12D.   X • 0 = 0nidempotency:3.   X + X = X3D.   X • X = Xninvolution:4.   (X’)’ = Xncomplementarity:5.   X + X’ = 15D.   X • X’ = 0ncommutativity:6.   X + Y = Y + X6D.   X • Y = Y • Xnassociativity:7.   (X + Y) + Z = X + (Y + Z)7D.   (X • Y) • Z = X • (Y • Z)Note that suffix “D” means the dual of the original expression. Dual is the other symmetric part of a pair, which will be discussed later. (at this moment, use two rules: AND<-> OR, 0<->1)Idempotency: one may derive the same consequences from many instances of a hypothesis as from just one Involution: a function that is its own inverse, so that f(f(x)) = x Axioms and theorems of Boolean algebra10Axioms and theorems of Boolean algebra (cont’d)ndistributivity:8.   X • (Y + Z) = (X • Y) + (X • Z)8D.   X + (Y • Z) = (X + Y) • (X + Z)nuniting:9.   X • Y + X • Y’ = X9D.   (X + Y) • (X + Y’) = Xnabsorption:10. X + X • Y = X10D.  X • (X + Y) = X11. (X + Y’) • Y = X • Y11D. (X • Y’) + Y = X + Ynfactoring:12. (X + Y) • (X’ + Z) =12D. X • Y + X’ • Z = X • Z + X’ • Y(X + Z) • (X’ + Y)nconcensus:13. (X • Y) + (Y • Z) + (X’ • Z) =13D. (X + Y) • (Y + Z) • (X’ + Z) =X • Y + X’ • Z(X + Y) • (X’ + Z)Theorem12. (X+Y)(X’+Z) = XX’+XZ+X’Y+YZ =XZ+X’Y+YZ(X+X’) =XZ(1+Y)+X’Y(1+Z) =XZ+X’Y11Axioms and theorems of Boolean algebra (cont’d)nde Morgan’s:14. (X + Y + ...)’ = X’ • Y’ • ...14D. (X • Y • ...)’ = X’ + Y’ + ...ngeneralized de Morgan’s:15. f’(X1,X2,...,Xn,0,1,+,•) =  f(X1’,X2’,...,Xn’,1,0,•,+)nestablishes relationship between • and +12Axioms and theorems of Boolean algebra (cont’d)nDualityqa dual of a Boolean expression is derived by replacing • by +, + by •, 0 by 1, and 1 by 0, and leaving variables unchangedqany theorem that can be proven is thus also proven for its dual!qa meta-theorem (a theorem about theorems) nduality:16. X + Y + ... ÛX • Y • ...ngeneralized duality:17. f (X1,X2,...,Xn,0,1,+,•) Ûf(X1,X2,...,Xn,1,0,•,+)nDifferent than deMorgan’s Lawqthis is a statement about theoremsqthis is not a way to manipulate (re-write) expressions13Proving theorems (rewriting)nUsing the axioms of Boolean algebra:qe.g., prove the theorem: X • Y + X • Y’ =   X   (uniting)\nqe.g., prove the theorem: X + X • Y =   X   (absorption)distributivity (8)X •Y + X •Y’=   X • (Y + Y’)complementarity (5)X • (Y + Y’) =   X •(1)identity (1D)X •(1)=   X üidentity (1D)X  +  X • Y=   X • 1  +  X • Ydistributivity (8)X • 1  +  X • Y=   X • (1 + Y)null (2)X • (1 + Y)=   X •(1)identity (1D)X • (1) =   X ü14(X + Y)’ = X’ • Y’NOR is equivalent to AND with inputs complemented(X • Y)’ = X’ + Y’NAND is equivalent to OR with inputs complementedXYX’Y’(X + Y)’X’ • Y’0011011010011100XYX’Y’(X • Y)’X’ + Y’0011011010011100Proving theorems (perfect induction)nUsing perfect induction (complete truth table):qe.g., de Morgan’s:100011101000111015A simple example: 1-bit binary addernInputs: A, B, Carry-innOutputs: Sum, Carry-outABCinCoutSABCinCoutS0000010100111001011101110110100100010111Cout = A’ B Cin + A B’ Cin + A B Cin’ + A B CinS = A’ B’ Cin + A’ B Cin’ + A B’ Cin’ + A B CinAAAAABBBBBSSSSSCinCout16adding extra terms creates new factoring opportunitiesApply the theorems to simplify expressionsnThe theorems of Boolean algebra can simplify Boolean expressionsqe.g., full adder’s carry-out function (same rules apply to any function)Cout =  A’ B Cin + A B’ Cin + A B Cin’ + A B Cin=  A’ B Cin  +  A B’ Cin  +  A B Cin’  +  A B Cin+  A B Cin=  A’ B Cin  +  A B Cin+  A B’ Cin  +  A B Cin’  +  A B Cin=  (A’ + A) B Cin  +  A B’ Cin  +  A B Cin’  +  A B Cin=  (1) B Cin  +  A B’ Cin  +  A B Cin’  +  A B Cin=  B Cin  +  A B’ Cin  + A B Cin’  +  A B Cin+  A B Cin=  B Cin  +  A B’ Cin  +  A B Cin+  A B Cin’  +  A B Cin=  B Cin  +  A (B’ + B) Cin  +  A B Cin’  +  A B Cin=  B Cin  +  A (1) Cin  +  A B Cin’  +  A B Cin=  B Cin  +  A Cin  +  A B (Cin’ +  Cin)=  B Cin  +  A Cin  +  A B (1)=  B Cin  +  A Cin  +  A B 17XYZ000010100111XY0110XYZ000011101111XYXXYYZZFrom Boolean expressions to logic gatesnNOTX’X~XnANDX • YXYX ÙYnORX + YX ÚY18XYZXYZ001011101110XYZ001010100110ZXYXYZXYZ001010100111XYZ000011101110ZXYX xorY = X Y’ + X’ YX or Y but not both (\"inequality\", \"difference\")X xnorY = X Y + X’ Y’X and Y are the same (\"equality\", \"coincidence\")From Boolean expressions to logic gates (cont’d)nNANDnNORnXORX ÅYnXNORX = YThe bubble at the tip indicates an inverter.XNOR is the negation of XOR19T1T2use of 3-input gateABCDT2T1ZABCDZFrom Boolean expressions to logic gates (cont’d)nMore than one way to map expressions to gatesqe.g.,  Z = A’ • B’ • (C + D) = (A’ • (B’ • (C + D)))20\ntime\nchange in Y takes time to \"propagate\" through gatesWaveform view of logic functionsnJust a sideways truth tableqbut note how edges don’t line up exactlyqit takes time for a gate to switch its output!\nThere IS difference; it takes time for a signal to pass through each gate.Waveform describes how a signal at each point changes over timeSuppose X and Y change at precise timing.Depending on the gate type, the gate passing delay can be slightly different. e.g. an XOR gate is complicated, which incurs a longer delay than other simple gates21ABCZ00000011010001111000101111011110\nChoosing different realizations of a functiontwo-level realization(we don’t count NOT gates)\nXOR gate (easier to draw but costlier to build)multi-level realization(gates with fewer inputs)p.53Z = A’B’C+ A’BC + AB’C + ABC’Z1 = ABC’ + A’C + B’CZ2 = ABC’ + (AB)’CZ3 = ABÅC\nZ1=Z2=Z3=ZLet’s consider Z1 first. 3 AND gates and 1 OR gate. Also we need to check the # of wires or inputs. In Z3, XOR is called a complex gate, which requires several NAND or NOR gates. So Z3 is likely to have the worst delay.22XOR implementationsnThree levels of logic inside a XOR gatenXÅY = X’Y + XY’XYXYXYXY23Which realization is best?nReduce number of inputsqliteral: input variable (complemented or not)•can approximate cost of logic gate as 2 transistors per literalqfewer literals means less transistors•smaller circuitsqfewer inputs implies faster gates•gates are smaller and thus also fasterqfan-ins (# of gate inputs) are limited in some technologiesnReduce number of gatesqfewer gates (and the packages they come in) means smaller circuits•directly influences manufacturing costs24Which is the best realization?  (cont’d)nReduce number of levels of gatesqfewer level of gates implies reduced signal propagation delaysqminimum delay configuration typically requires more gates•wider, less deep circuitsnHow do we explore tradeoffs between increased circuit delay and size?qautomated tools to generate different solutionsqlogic minimization: reduce number of gates and complexityqlogic optimization: reduction while trading off against delayDepending on the criteria (e.g. minimize delay, minimize the # of gates), the CAD tools may yield different solutions.25\nAre all realizations equivalent?nUnder the same input stimuli, the three alternative implementations have almost the same waveform behaviorqdelays are differentqglitches (hazards) may arise –these could be bad, it dependsqvariations due to differences in number of gate levels and structurenThe three implementations are functionally equivalent\nDifferent implementations for the same function are equivalent with a steady state viewpoint, but the transient behavior may be a little bit differentTypically, a transient behavior takes place right after some input transition. 26ABCZ00000011010001111000101111011110\nChoosing different realizations of a functiontwo-level realization(we don’t count NOT gates)\nXOR gate (easier to draw but costlier to build)multi-level realization(gates with fewer inputs)A = 1\nLet’s see Z2. First, input variables are changing. B goes from 0 to 1 while C goes from 1 to 0, and these changes are propagated through gates. The delays are accumulated as the signal goes through more gates. B = 0 → 1C = 1 → 0\n0→11→1→00→0→11→0→ 0→0 1→1 → 0→1 Assume the same delay for all gatesABC’CGlitch!27Implementing Boolean functionsnTechnology independentqcanonical formsqtwo-level formsqmulti-level formsnTechnology choicesqpackages of a few gatesqregular logicqtwo-level programmable logicqmulti-level programmable logicA Boolean function can take one of various expressions.28Canonical formsnTruth table is the unique signature of a Boolean functionnThe same truth table can have many gate realizationsnCanonical formsqstandard forms for a Boolean expressionqprovides a unique algebraic signature29ABCFF’0000100110010010111010001101101101011110F =F’ = A’B’C’ + A’BC’ + AB’C’Sum-of-products (S-o-P) canonical formsnAlso known as (aka) disjunctive normal formnAlso known as minterm expansionF =  001      011      101       110       111+ A’BC+ AB’C+ ABC’+ ABCA’B’C\nJust check all the cases when F becomes true and each case forms the product of input variables. And finally, ORing these products will yield the final expression.This is also called minterm expansion; here, a minterm is aproduct of all the input literals. Each literal should appear once in each minterm: asserted or complemented 30short-hand notation forminterms of 3 variablesABCminterms000A’B’C’m0001A’B’Cm1010A’BC’m2011A’BCm3100AB’C’m4101AB’Cm5110ABC’m6111ABCm7F in canonical form:F(A, B, C)= Sm(1,3,5,6,7)=  m1 + m3 + m5 + m6 + m7=  A’B’C + A’BC + AB’C + ABC’ + ABCcanonical form ¹minimal formF(A, B, C)= A’B’C + A’BC + AB’C + ABC + ABC’ = (A’B’ + A’B + AB’ + AB)C + ABC’= ((A’ + A)(B’ + B))C + ABC’= C + ABC’= ABC’ + C= AB + CSum-of-products canonical form (cont’d)nProduct term (or minterm)qANDed product of literals –input combination for which output is trueqeach variable appears exactly once, true or inverted (but not both)01234567Each product is called a minterm, and denoted by small mand a decimal numberfor the binary input valuesNote that there is no reduction or minimization in canonical forms; each variable must appear once for each product31ABCFF’0000100110010010111010001101101101011110F =       000              010              100F =\nF’ = (A + B + C’) (A + B’ + C’) (A’ + B + C’) (A’ + B’ + C) (A’ + B’ + C’)Product-of-sums (P-o-S) canonical formnAlso known as conjunctive normal formnAlso known as maxterm expansion(A + B + C)(A + B’ + C)(A’ + B + C)\nThe other canonical form is P-o-S. This one focuses on when F will be 0.P-o-S is like the dual of S-o-P. First of all, we check all the cases that make F false or 0The variables for each case or term are first complemented and then connected by the OR operation. This ORed term is called a maxterm. Eventually, these terms are connected by AND. What does the final expression mean?32ABCmaxterms000A+B+CM0001A+B+C’M1010A+B’+CM2011A+B’+C’M3100A’+B+CM4101A’+B+C’M5110A’+B’+CM6111A’+B’+C’M7short-hand notation formaxterms of 3 variablesF in canonical form:F(A, B, C)= PM(0,2,4)=  M0 • M2 • M4=  (A + B + C) (A + B’ + C) (A’ + B + C)canonical form ¹minimal formF(A, B, C)= (A + B + C) (A + B’ + C) (A’ + B + C)= (A + B + C) (A + B’ + C)(A + B + C) (A’ + B + C)= (A + C) (B + C)Product-of-sums canonical form (cont’d)nSum term (or maxterm)qORed sum of literals –input combination for which output is falseqeach variable appears exactly once, true or inverted (but not both)\nEach maxterm is denoted by the capital Mand the decimal value of input variables.33S-o-P, P-o-S, and de Morgan’s theoremnSum-of-productsqF’ = A’B’C’ + A’BC’ + AB’C’nProduct-of-sums for F??nApply de Morgan’sq(F’)’ = (A’B’C’ + A’BC’ + AB’C’)’qF = (A + B + C) (A + B’ + C) (A’ + B + C)nProduct-of-sumsqF’ = (A + B + C’) (A + B’ + C’) (A’ + B + C’) (A’ + B’ + C) (A’ + B’ + C’)nSum-of-products for F?nApply de Morgan’sq(F’)’ = ( (A + B + C’)(A + B’ + C’)(A’ + B + C’)(A’ + B’ + C)(A’ + B’ + C’) )’qF = A’B’C + A’BC + AB’C + ABC’ + ABC34canonical sum-of-productsminimized sum-of-productscanonical product-of-sumsminimized product-of-sumsF1F2F3BAC\nF4Four alternative two-level implementationsof F = AB + C35\nWaveforms for the four alternativesnWaveforms are essentially identicalqexcept for timing hazards (glitches)qdelays almost identical (modeled as a delay per level, not type of gate or number of inputs to gate)\nEven though F1, F2, F3 and F4 are equivalent in steady-state behaviors, their transient behaviors may be different36Mapping between canonical formsnMinterm to maxterm conversionquse maxterms whose indices do not appear in minterm expansionqe.g., F(A,B,C) = Sm(1,3,5,6,7) = PM(0,2,4)nMaxterm to minterm conversionquse minterms whose indices do not appear in maxterm expansionqe.g., F(A,B,C) = PM(0,2,4) = Sm(1,3,5,6,7) nMinterm expansion of F to minterm expansion of F’quse minterms whose indices do not appearqe.g., F(A,B,C) = Sm(1,3,5,6,7) F’(A,B,C) = Sm(0,2,4)nMaxterm expansion of F to maxterm expansion of F’quse maxterms whose indices do not appearqe.g., F(A,B,C) = PM(0,2,4) F’(A,B,C) = PM(1,3,5,6,7)37ABCDWX YZ000000010001001000100011001101000100010101010110011001110111100010001001100100001010XXXX1011XXXX1100XXXX1101XXXX1110XXXX1111XXXXoff-set of W\nthese inputs patterns should never be encountered in practice –\"don’t care\"about associated output values, can be exploitedin minimizationIncompletely specified functionsnExample: binary coded decimal (BCD) increment by 1qBCD digits encode the decimal digits 0 –9 in the bit patterns 0000 –1001don’t care (DC) set of Won-set of W\nBCD coding uses only ten values from 0 to 9. With 4 input lines, we have 6 don’t care cases of input values. For these don’t care values, the function can have any arbitrary output valuesOn-set: the set of cases whose output is 138Notation for incompletely specified functionsnDon’t cares and canonical formsqso far, we focus on either on-set or off-setqThere can be don’t-care-setqneed two of the three sets (on-set, off-set, dc-set)nCanonical representations of the BCD increment by 1 function:qMinterm expansion?qZ = m0 + m2 + m4 + m6 + m8 + d10 + d11 + d12 + d13 + d14 + d15qZ = S[ m(0,2,4,6,8) + d(10,11,12,13,14,15) ]qMaxterm expansion?qZ = M1 • M3 • M5 • M7 • M9 • D10 • D11 • D12 • D13 • D14 • D15qZ = P[ M(1,3,5,7,9) • D(10,11,12,13,14,15) ]39Simplification of two-level combinational logicnFinding a minimal sum of products or product of sums realizationqexploit don’t care information in the processnAlgebraic simplificationqnot an algorithmic/systematic procedureqhow do you know when the minimum realization has been found?nComputer-aided design (CAD) toolsqprecise solutions require very long computation times, especially for functions with many inputs (> 10)qheuristic methods employed –\"educated guesses\" to reduce amount of computation and yield good if not best solutionsnHand methods still relevantqto understand automatic tools and their strengths and weaknessesqability to check results (on small examples)40Two minimization techniquesnBoolean cubesnKarnaugh-maps (K-maps)nBoth of them are based on the uniting theorem41ABF001010101110B has the same value in both on-set rows–B remains (in complemented form)A has a different value in the two rows–A is eliminatedF = A’B’+AB’ = (A’+A)B’ = B’The uniting theoremnKey tool to simplification: A (B’ + B) = AnEssence of simplification of two-level logicqfind two element subsets of the ON-set where only one variable changes its value –this single varying variable can be eliminated and a single product term used to represent both elements421-cubeX01Boolean cubesnVisual technique for identifying when the uniting theoremcan be appliednn input variables = n-dimensional \"cube\"2-cubeXY110001103-cubeXYZ0001111014-cubeWXYZ000011111000011143ABF001010101110ON-set = solid nodesOFF-set = empty nodesDC-set = ´'d nodestwo faces of size 0 (nodes) combine into a face of size 1(line)\nA varies within face, B does notthis face represents the literal B'Mapping truth tables onto Boolean cubesnUniting theorem combines two \"faces\" of a cubeinto a larger \"face\"nExample:AB11000110F\nfill in the nodes that correspond to the elements of the ON-set.If there are two adjacent solid nodes, we can use the uniting theorem. 44ABCinCout00000010010001111000101111011111Cout = BCin+AB+ACinThree variable examplenBinary full-adder carry-out logic(A'+A)BCinAB(Cin'+Cin)A(B+B')Cinthe on-set is completely covered by the combination (OR) of the subcubes of lower dimensionality -note that “111”is covered three timesABC00011110110001001145F(A,B,C) = Sm(4,5,6,7)A is asserted (true) and unchangedB and C varyThis subcube represents theliteral AHigher dimensional cubesnSub-cubes of higher dimension than 2\nABC000111101100001010011110Output function is Sm(4,5,6,7) in S-O-P form.In this case, the on-set nodes form a square.Here, we use the uniting theorem at a greater scale. A(BC+BC’+B’C+B’C’) = Aon-set forms a squarei.e., a cube of dimension 2represents an expression in one variable       i.e., 3 dimensions  –2 dimensions46m-dimensional cubes in a n-dimensional Boolean spacenIn a 3-cube (three variables):qa 0-cube, i.e., a single node, yields a term in 3 literalsqa 1-cube, i.e., a line of two nodes, yields a term in 2 literalsqa 2-cube, i.e., a plane of four nodes, yields a term in 1 literalqa 3-cube, i.e., a cube of eight nodes, yields a constant term \"1\"nIn general,qIn an n-cube, an m-subcube (m < n) yields a termwith n –m literals47ABF001010101110Karnaugh mapsnFlat map of Boolean cubeqwrap–around at edgesqhard to draw and visualize for more than 4 dimensionsqvirtually impossible for more than 6 dimensionsnAlternative to truth-tables to help visualize adjacenciesqguide to applying the uniting theoremqon-set elements with only one variable changing value are adjacent unlike the situation in a linear truth-table021301AB011001Another technique is using a Karnaugh map, which is kind of a flat version of the Boolean cube technique. 48Karnaugh maps (cont’d)nNumbering scheme based on Gray–codeqe.g., 00, 01, 11, 10qonly a single bit changes in code for adjacent map cells02130001ABC0164751110CBA\n02136475CBA0415128139DA372615111410CB13 = 1101= ABC’DThis slide shows Karnaugh maps of 3 and 4 inputs . The thick line segment represents the domain (in the perpendicular direction) where each variable is always TRUE.The complement of the above domain indicate the inverted variable. 10110100\n* Gray code: two successive numbers differ in only one bit and they are cyclic49Adjacencies in Karnaugh mapsnWrap from first to last columnnWrap top row to bottom row000010001011110100111101CBAABC000111101100001010011110Let’s focus on cell 000; there are three adjacent cells.Note that the number of adjacent cells is the same as the number of input variables since it is equal to the number of bits.50The on-set included in the red oval is already covered by two other adjacenciesKarnaugh map examplesnF =nCout =nf(A,B,C) = Sm(0,4,5,7) 00011011CinBA1100BA\n10000111CBAB’ABAC+ ACin+ BCin+ B’C’+ AB’51F(A,B,C) = Sm(0,4,5,7)F'(A,B,C) = Sm(1,2,3,6)F' simply replace 1's with 0's and vice versaG(A,B,C) = More Karnaugh map examples00001111CBA\n10000111CBA\n01111000CBAA= AC + B’C’= BC’ + A’C52C+ B’D’\nfind the smallest number of the largest possible subcubes to cover the ON-set(fewer terms with fewer inputs per term)Karnaugh map: 4-variable examplenF(A,B,C,D) = Sm(0,2,3,5,6,7,8,10,11,14,15)F =DA\nBABCD00001111100001111001010011111111C+ A’BD53+ B’C’DKarnaugh maps: don’t cares (DCs)nf(A,B,C,D) = Sm(1,3,5,7,9) + d(6,12,13)qwithout don't cares•f = A’D0011X0X1DA110X0000BCNow let’s see how we can utilize don’t care (DC) terms in the Karnaugh map technique. If we don’t use DC terms, the logic function f is A’D +B’C’D54Karnaugh maps: don’t cares (cont’d)nf(A,B,C,D) = Sm(1,3,5,7,9) + d(6,12,13)qf = A'D + B'C'Dwithout don't caresqf = with don't cares\ndon't carescan be treated as 1s or 0sdepending on which is more advantageous0011X0X1DA110X0000BCA'Dby using don't care as a \"1\"a 2-cube can be formed rather than a 1-cube to coverthis node+ C'D\nBy interpreting DCs as 1s opportunistically, we can utilize the uniting theorem at greater scale.55Combinational logic summarynLogic functions, truth tables, and switchesqNOT, AND, OR, NAND, NOR, XOR, . . ., minimal setnAxioms and theorems of Boolean algebraqproofs by re-writing and perfect inductionnGate logicqnetworks of Boolean functions and their time behaviornCanonical formsqtwo-level and incompletely specified functionsnSimplificationqa start at understanding two-level simplificationnLaterqautomation of simplificationqmulti-level logicqtime behaviorqhardware description languagesqdesign case studies"
    },
    {
        "document_id": "Lecture03_WorkComb.pdf",
        "text": "1Chapter 3working with combinational logic2Working with combinational logicnSimplificationqtwo-level simplificationqexploiting don’t caresqalgorithm for simplificationnLogic realizationqtwo-level logic and canonical forms realized with NANDs and NORsqmulti-level logic, converting between ANDs and ORsnTime behaviornHardware description languagesThe first important topic here is formalizing the process of boolean minimization. In the last chapter, we illustrated how logic functions (or its expressions) can be simplified by boolean cubes or K-maps. Here we will look at a systematic or algorithmic approach.3we'll need a 4-variable Karnaugh map for each of the 3 output functionsDesign example: two-bit comparator\nblock diagramLTEQGTA B < C DA B = C DA B > C DABCDN1N2ABCDLTEQGT0000010011001010011100010000101010101001110010000010100110010111001100001010011000111010andtruth tableBefore going into the formal minimization process, let’s look at some examples.The first example compares two numbers, each of which is two bits long, N1 is AB and N2 is CD, where A and C are most significant bits (MSBs) while B and D are least significant bits (LSBs).4A' B' D  +  A' C  +  B' C DB C' D'  +  A C'  +  A B D'LT=EQ=GT=K-map for EQK-map for LTK-map for GTDesign example: two-bit comparator (cont’d)00100000DA11110100BC10010000DA00001001BC01001111DA00000010BC= (A xnor C) • (B xnor D)A' B' C' D'  +  A' B C' D  +  A B C D  +  A B' C D’EQ = (AC +A’C’)BD + (AC+A’C’)B’D’=(AC+A’C’)(BD+B’D’)5two alternativeimplementations of EQwith and without XORXNOR is implemented with at least 3 simple gatesABCDEQEQDesign example: two-bit comparator (cont’d)64-variable K-mapfor each of the 4output functionsA2A1B2B1P8P4P2P100000000010000100000110000010000000100011000101100111000000001001010010011011011000000010011100110111001Design example: 2x2-bit multiplier\nThis is a 2bit-by-2bit multiplier that generates 4 bit output (whose MSB is P8 and LSB is P1). Note that A2 and B2 are MSBs.block diagramandtruth tableP1P2P4P8A1A2B1B27K-map for P8K-map for P4\nK-map for P2K-map for P1Design example: 2x2-bit multiplier (cont’d)00000000B1A200000111A1B200010010B1A201001000A1B200000011B1A201010110A1B200000000B1A200001000A1B2P8 = A2A1B2B1P4= A2B2B1'+ A2A1'B2\nP2= A2'A1B2+ A1B2B1'+ A2B2'B1+ A2A1'B1P1= A1B18I8I4I2I1O8O4O2O1000000010001001000100011001101000100010101010110011001110111100010001001100100001010XXXX1011XXXX1100XXXX1101XXXX1110XXXX1111XXXXblock diagramandtruth table4-variable K-map for each of the 4 output functionsO1O2O4O8I1I2I4I8Design example: BCD increment by 19O8 = I4 I2 I1 + I8 I1'O4 = I4 I2' + I4 I1' + I4’ I2 I1O2 = I8’ I2’ I1 + I2 I1'O1 = I1'O8O4\nO2O1Design example: BCD increment by 1 (cont’d)0000X1X0I1I80100XXXXI4I20011X0X0I1I80011XXXXI4I20101X0X0I1I81001XXXXI4I21100X1X0I1I80011XXXXI4I2In O8, we will interpret a don’t care (DC) term as 1 if it helps to minimize the number of literals for the elements of the ON-set. The other DC terms will be treated as 0. To minimize the number of literals, we have to find out the maximum size subcube.10Definition of terms for two-level simplificationnImplicantqsingle element of ON-set or DC-set or any group of these elements that can be combined to form a subcube (or an adjacent group)nPrime implicant (PI)qimplicant that can't be combined with another to form a larger subcubenEssential prime implicantqprime implicant is essential if it alone covers an element of ON-setqwill participate in ALL possible covers of the ON-setqDC-set used to form prime implicants but not to make implicant essentialnObjective:qgrow implicant into prime implicants(to minimize literals per term)qcover the ON-set with as few prime implicants as possible(to minimize number of product terms)So far we have examined a few examples of logic design simplificationFrom now on, we will try to perform simplification in a systematic or algorithmic way. To do so, we first have to define some terminologies.110X111010DA10001111BC5 prime implicants:BD, ABC', ACD, A'BC, A'C'DExamples to illustrate terms\n00111010DA01011100BC6 prime implicants:A'B'D, BC', AC, A'C'D, AB, B'CDminimum cover: AC + BC'+ A'B'Dessential\nminimum cover: 4 essential implicantsessentialFirst of all, we have to find out all the possible prime implicants. Then we first transform the essential prime implicants to boolean expressions. Then we will try to find the minimum set of prime implicants to cover the entire on-set, called minimum cover.12Algorithm for two-level simplificationnAlgorithm: minimum sum-of-products expression from a Karnaugh mapqStep 1: choose an element of the ON-setqStep 2: find \"maximal\" groupings of 1s and Xs adjacent to that elementnconsider top/bottom row, left/right column, and corner adjacenciesnthis forms prime implicants  (number of elements always a power of 2)qRepeat Steps 1 and 2 to find all prime implicantsqStep 3: revisit the 1s in the K-mapnif covered by single prime implicant, it is essential, and participates in final covern1s covered by essential prime implicant do not need to be revisitedqStep 4: if there remain 1s not covered by essential prime implicantsnselect the smallest number of prime implicants that cover the remaining 1sFor all 1s, check the PIs that include the 1. The PIs should be considered for all the 1s and DCs around that can be united. Then we first choose essential PIs and then find out the minimum cover, the minimum number of PIs that cover the remaining 1s.13X1010111DA0X01X001BC3 primes around AB'C'D'Algorithm for two-level simplification (example)X1010111DA0X01X001BC2 primes around A'BC'D'X1010111DA0X01X001BC2 primes around ABC'DX1010111DA0X01X001BC\nminimum cover (3 primes)X1010111DA0X01X001BCX1010111DA0X01X001BC2 essential primesX1010111DA0X01X001BCIII -Working with Combinational Logic© Copyright 2004, Gaetano Borriello and Randy H. Katz1414ActivityX001X0X1DA0XX1X011BCBCBD AB AC’DCD’BDCD’AC’DBDCD’AC’DnList all prime implicants for the following K-map:\nnWhich are essential prime implicants?nWhat is the minimum cover?X001X0X1DA0XX1X011BC\nLet’s start with prime implicants. Among PIs, check which are essential. Finally, we should find out the minimum cover, which is the minimum number of PIs that cover all the elements of the ON-set (including essential PIs)15Implementations of two-level logicnSum-of-productsqAND gates to form product terms (minterms)qOR gate to form sum\nnProduct-of-sumsqOR gates to form sum terms (maxterms)qAND gates to form productIn this section, we will focus on how to implementlogic networks with NAND or NOR gates. Again there are two kinds of canonical forms: S-O-P and P-O-S. A small circle is an inverter.A B C16Two-level logic using NAND gatesnReplace minterm AND gates with NAND gatesnPlace compensating inversion at inputs of OR gate\nNAND/NOR gates requires less CMOS TRs than AND/OR gates. So we want to change AND/OR gates into NAND gates only (or NOR gates only)The simplest way is to insert double inverters between AND and OR gates. Then what happens is that AND becomes NAND just by placing bubbles. How about the OR gate?A B CA B C17Two-level logic using NAND gates (cont’d)nOR gate with inverted inputs is a NAND gateqde Morgan’s:A’ + B’ = (A • B)’nTwo-level NAND-NAND networkqinverted inputs are not countedqin a typical circuit, inversion is done once and signal distributed\nRecall de Morgan’s Law. When inverters are passing through a gate, the gate should be changed from OR to AND and vice versa.18Two-level logic using NOR gatesnReplace maxterm OR gates with NOR gatesnPlace compensating inversion at inputs of AND gate\nIn the case of P-O-S forms, the same technique is used; however, this time, the NOR gate is the results of conversion. Again, we insert two bubbles between OR and AND gates and push those bubbles in the opposite directions.19Two-level logic using NOR gates (cont’d)nAND gate with inverted inputs is a NOR gateqde Morgan’s:A’ • B’ = (A + B)’nTwo-level NOR-NOR networkqinverted inputs are not countedqin a typical circuit, inversion is done once and signal distributed\nUsing de Morgan’s theorem again, the AND gate with inverted inputs is transformed into the NOR gate as shown in the above.20Two-level logic using NAND and NOR gatesnNAND-NAND and NOR-NOR networksqde Morgan’s law:(A + B)’=   A’ • B’(A • B)’  =   A’ + B’qwritten differently:A + B=  (A’ • B’)’(A • B)   =  (A’ + B’)’nIn other words ––qOR is the same as NAND with complemented inputsqAND is the same as NOR with complemented inputsqNAND is the same as OR with complemented inputsqNOR is the same as AND with complemented inputsThis slide summarizes what I explained about conversion from AND-OR combination to either NAND or NOR gates. All the conversions are just variations of de morgan’s theorem.21ABCDZABCDZNANDNANDNANDConversion between formsnConvert from networks of ANDs and ORs to networks of NANDs and NORsqintroduce appropriate inversions (\"bubbles\")nEach introduced \"bubble\" must be matched by a corresponding \"bubble\"qconservation of inversionsqdo not alter logic functionnExample: AND/OR to NAND/NANDAgain, inverters inserted between gates are called bubbles. In order to make no changes in the logic function, the bubbles are always paired.22Z = [ (A  •  B)’  • (C   • D)’  ]’= [ (A’ + B’)  •  (C’ + D’)  ]’= [ (A’ + B’)’ + (C’ + D’)’  ]=   (A  •  B)   + (C  • D)  üConversion between forms (cont’d)nExample: verify equivalence of two formsABCDZABCDZNANDNANDNAND\nLet’s verify the conversion rule by boolean expressions and boolean theorems23conserve\"bubbles\"Step 1conserve\"bubbles\"Step 2NORNORNOR\\A\\B\\C\\DZNORNORABCDZConversion between forms (cont’d)nExample: map AND/OR network to NOR/NOR networkABCDZ\nWhen an input variable, say A, is complemented, it is denoted by \\A When a S-o-P canonical form is converted to NOR networks, we have to insert two bubbles at the input stage. And the same thing happens at the output stage.24Z = {  [ (A’ + B’)’ + (C’ + D’)’  ]’  }’= {     (A’ + B’)  •  (C’ + D’)      }’=       (A’ + B’)’ + (C’ + D’)’=       (A  •  B)  +  (C  •  D)   üConversion between forms (cont’d)nExample: verify equivalence of two formsABCDZNORNORNOR\\A\\B\\C\\DZ\nThis is the boolean logic proof of the conversion in the previous slide.25ABCDEFGXMulti-level logicnx = A D F  +  A E F  +  B D F  +  B E F  +  C D F  +  C E F  +  Gqreduced sum-of-products form –already simplifiedq6 x 3-input AND gates + 1 x 7-input OR gate (that may not even exist!)q25 wires (19 literals plus 6 internal wires)nx = (A + B + C) (D + E) F  +  Gqfactored form –not written as two-level S-o-Pq1 x 3-input OR gate, 2 x 2-input OR gates, 1 x 3-input AND gateq10 wires (7 literals plus 3 internal wires)If there are common parts in a canonical form, it may be better to use multi-level logic to reduce the number of literals and gates at the cost of delay. Again tradeoff between delay and gate countLevel 1Level 2Level 3Level 4originalAND-OR networkACDBB\\CFintroduction andconservation of bubblesACDBB\\CFredrawn in termsof conventionalNAND gatesACD\\BB\\CFConversion of multi-level logic to NAND gatesnF = A (B + C D) + B C’\nNormally when we add two bubbles in a wire, two levels are converted to NAND gates. Here we add two bubbles between AND and OR gates.2627Conversion between formsnExampleAXBCDForiginal circuitAXBCDFadd double bubbles to invert all inputs of OR gate\\DABCF\\DAXBCF\\Xinsert inverters to eliminate double bubbles on a wireadd double bubbles to invert output of AND gateXThis slide illustrates how we can convert a combination of AND and OR gates into NAND and NOT gates. As mentioned before, NOT gates can be replaced by NAND gates by splitting the input.28Level 1Level 2Level 3Level 4ACDBB\\CForiginalAND-OR networkintroduction andconservation of bubblesACDBB\\CFConversion of multi-level logic to NORsnF = A (B + C D) + B C’\nHere we add bubbles in different position to use NOR gates. Note that the final inverter is implemented by NOR!redrawn in termsof conventionalNOR gates\\A\\C\\DB\\BCF.29&&+2x2 AOI gatesymbol&&+3x2 AOI gatesymbolNANDNANDInvertpossible implementationABCDZANDORInvertlogical conceptABCDZAND-OR-Invert (AOI) gatesnAOI function:  three stages of logic —AND, OR, Invertqmultiple gates \"packaged\" as a single circuit block\nHere is a special case of AND-OR-Inverter gates, which is a popular combination in a logic package. The reason it becomes a popular combination is that it can be implemented compactly with CMOS TRs.30AOI examplenWhy AOI is more compact than NAND or NOR?out = [ab+c]’:\ncircuitandorinvertsymbol3vXY0vZ10v3vXYZ2NORNAND31&&+A’B’ABFConversion to AOI formsnGeneral procedure to place in AOI formqcompute the complement of the function in sum-of-products formqby grouping the 0s in the Karnaugh mapnExample:  XOR implementationqA xor B = A’ B  +  A B’qAOI form:nF = (A’ B’  +  A B)’Let’s take an example to use AOI to implement a logic function. Suppose we have to implement a XOR function. F = AB’+A’B. first of all, we consider F’ (note that there is an inverter at the end of AOI). F’ = AB+A’B’. So we implement F’ in the SOP form.32Summary for multi-level logicnAdvantagesqcircuits may be smallerqgates have smaller fan-innDisadvantagesqcircuits will be slowerqmore difficult to designqtools for optimization are not as good as for two-levelqanalysis is more complexMulti-level logic design can reduce the number of gates or at least the number of fan-ins of gates. However, optimization is more complex.33Time behavior of combinational networksnWaveformsqvisualization of values carried on signal wires over timequseful in explaining sequences of events (changes in value)nSimulation tools are used to create these waveformsqinput to the simulator includes gates and their connectionsqinput stimulus, that is, input signal waveformsnSome termsqgate delay —time for change at input to cause change at outputnmin delay –typical/nominal delay –max delayncareful designers design for the worst caseqrise time —time for output to transition from low to high voltageqfall time —time for output to transition from high to low voltageqpulse width —time that an output stays high or stays low between changesThe next topic of this chapter is the behavior of combinational logic as time goes by.The waveform of a system can be simulated by a tool considering gates and their connections. The output of the system is triggered by the input stimulus. 34\nF is not always 0pulse 3 gate-delays wideD remains high forthree gate delays afterA changes from low to highFABCDMomentary changes in outputsnCan be useful —pulse shaping circuitsnCan be a problem —incorrect circuit operation (glitches/hazards)nExample: pulse shaping circuitqA’ • A = 0qdelays matter\nLet’s see how a waveform changes over time in this case. Here, each gate is assumed to incur 10 time unit delay. This time-varying behavior is utilized to make a periodic pulse.35\ninitially undefinedclose switchopen switch+open switchresistorABCDOscillatory behaviornAnother pulse shaping circuit\nAssume that each gate delay is 10 time units. Here, the output of NAND is feedback to its input with a couple of inverters. Let’s look at the waveform of B. what does it look like?36Hardware description languages (HDLs)nDescribe hardware at varying levels of abstractionnStructural descriptionqtextual replacement for schematicqhierarchical composition of modules from primitivesnData-flow style descriptionqtextual replacement of truth tablenBehavioral/functional descriptionqdescribe what module does, not howqsynthesis generates circuit for modulenSimulation semanticsThis is the last topic of chapter 3.So far, we rely on boolean expressions and schematic drawings to describe logic functions. However, as a logic function gets complicated, it will become extremely hard to write and understand the logic system. Hierarchy can help to mitigate this problem; but it is not enough. HDLs are proposed to deal with this problem.Using HDLs, we can describe any complicated logic system. Moreover, the languages can be executed, they run like s/w. A program emulates the behavior of the designed system as faithfully as possible. It radically reduces the time to design a system37HDLsnAbel (circa 1983) -developed by Data-I/Oqtargeted to programmable logic devicesqnot good for much more than state machinesnISP (circa 1977) -research project at CMUqsimulation, but no synthesisnVerilog (circa 1985) -developed by Gateway (absorbed by Cadence)qsimilar to Pascal and Cqdelay is only interaction with simulatorqfairly efficient and easy to writeqIEEE standardnVHDL (circa 1987) -DoD sponsored standardqsimilar to Ada (emphasis on re-use and maintainability)qsimulation semantics visibleqvery general but verboseqIEEE standardVerilog and VHDL are the most popular HDLs.V: very high speed ICThis course does not aim to cover HDLs in-depth.Verilog powernAlternative to schematics (interconnection of components)nMuch more powerful than schematicsqBoolean eqs.qTruth tableqComplex operations (addition, …)nRepresent entire system –designed as a hierarchynMany tools availableVerilog design examplenDesign half of a 74x139 (Dual 2-to-4 decoder)qThree different types of programming (description)nStructural descriptionnData-flow style descriptionnBehavioral description74x139\nG\nA_LB_LA_iB_iU1U2U3U4U5U6U7U8U9Behavioral DescriptionnTo this point, structural and data-flow description àalternatives of schematic and truth tablenBehavioral description: richest set of language element àalgorithmic description of hardwarenMain element: alwaysalways @ (signal_name1, signal_name2, …)begin--------endSensitivity listSequential statements-loops-case statements-if-then-elseVerilog design flow\n½ 74x139 timing diagram½ 74x139 fitting resultMagnification of a MC (Macrocell)Hierarchical Design (2 ´½74x139)\n50HDLs vs. programming languages (PLs)nProgram structureqinstantiation of multiple components of the same typeqspecify interconnections between modules via schematicqhierarchy of modules nAssignmentqcontinuous assignment (logic always computes)qpropagation delay (computation takes time)qtiming of signals is important (when does computation have its effect)nData structuresqsize explicitly spelled out -no dynamic structures qno pointersnParallelismqhardware is naturally parallel (must support multiple threads)qassignments can occur in parallel (not just sequentially)Even though a hierarchical structure is common on HDLs and PLs, there are some fundamental differences between HDLs and PLs.For example, continuous assignment and propagation delay are not typically supported in PLs.51HDLs and combinational logicnModules -specification of inputs, outputs, bidirectional, and internal signalsnContinuous assignment -a gate’s output is a function of its inputs at all times (doesn’t need to wait to be \"called\")nPropagation delay-concept of time and delay in input affecting gate outputnComposition -connecting modules together with wiresnHierarchy -modules encapsulate functional blocksHDLs can describe every aspect of combinational logic systems.52Working with combinational logic summarynDesign problemsqfilling in truth tablesqincompletely specified functionsqsimplifying two-level logicnRealizing two-level logicqNAND and NOR networksqnetworks of Boolean functions and their time behaviornTime behaviornHardware description languagesnLaterqcombinational logic technologiesqmore design case studies"
    },
    {
        "document_id": "Lecture04_CombTech.pdf",
        "text": "1Chapter 4.Combinational logic technologies\n© Copyright 2004, Gaetano Borriello and Randy H. Katz2Combinational Logic TechnologiesnStandard gates (random logic)qgate packagesqcell librariesnRegular logicqmultiplexersqdecoders nTwo-level programmable logicqPALsqPLAsqROMsThe simplest way to implement logic circuits would be using standard gates. However, as more complicated and diverse logic systems are getting required, a wealth of implementation techniques are proposed. There are three major categories in logic implementation technologies.\n3Random logicnTransistors quickly integrated into logic gates (1960s)nCatalog of common gates (1970s)qTexas Instruments Logic Data Book –the yellow bibleqall common packages listed and characterized (delays, power)qtypical packages: nin 14-pin IC: 6-inverters, 4 NAND gates, 4 XOR gatesnToday, very few parts are still in usenHowever, parts libraries exist for chip designqdesigners reuse already characterized logic gates on chipsAgain it is easy and simple to use standard gates such as NAND and AND, called random logic. Since a single gate is not good to sell and buy, a few or several gates are packed into a package. Right now, it is not widely used for economical reasons since there are a lot of IC packages in the catalog.4Regular logicnNeed to make design fasternNeed to make engineering changes easier to makenMUX and DEMUXUnlike random logic, regular logic refers to a flexible component that performs a specific high-level function compared to primitive logic gates. Design becomes easier with these regular logic components since each component performs a specific function. Sometimes we can flexibly exploit the regular logic components for other purposes than its original one. 5multiplexerdemultiplexer4x4 switchcontrolcontrolMaking connectionsnDirect point-to-point connections between gatesqwires we've seen so farnRoute one of many inputs to a single output -multiplexer (MUX)nRoute a single input to one of many outputs -demultiplexer (DEMUX)\nTwo popular regular logic components are MUX and DEMUX. A MUX selects one of its data inputs to the output by the control inputs; a MUX is also called a selector. The diagram on the left shows a 4-input MUX. Can you guess the relation between the number of data inputs and the number of control lines? A DEMUX performs the reverse function, often called a decoder. We can clearly see that these components perform higher-level functions compared to logic gates6Mux and demuxnSwitch implementation of multiplexers and demultiplexersqcan be composed to make arbitrary size switching networksqused to implement multiple-source/multiple-destination interconnectionsABYZABYZWhen we combine MUXs and DEMUXs, a switching network can be implemented. Note that control lines are skipped here.In this slide, there are 2X2 switching networks. By using control variables (which are skipped), A and B can be routed to either Y or Z.7multiple input sources\nmultiple output destinationsMUXABSumSsSbB0MUX\nDEMUXMux and demux (cont'd)nUses of multiplexers/demultiplexers in multi-point connectionsB1A0A1\nS0S1Let’s see how MUX and DEMUX can be used for a logic system design. Here is a 1-bit adder, a V-shape polygon. There are two sources for each input and two destinations for the resulting sum. So there are total three control variables.Sa8two alternative formsfor a 2:1 Mux truth tablelogical formAZ0I01I1I1I0AZ00000010010101101000101111011111Z = A' I0+ A I1Multiplexers (MUXs)/selectorsnMultiplexers/selectors: general conceptq2ndata inputs, n control inputs (called \"selects\"), 1 outputqused to connect 2npoints to a single pointqcontrol signal pattern forms binary index of input connected to outputfunctional formLet’s look at how a MUX function can be described as a boolean expression or a truth table. We will start with the simplest one, 2:1 MUX. There are two inputs I0 and I1 and the control input is A. Then Z will select I0 or I1 depending on A’s value. If we tabulate all the cases of I0 and I1, the final truth table is the one on the right.92   -1I0I1I2I3I4I5I6I7A  B  C8:1muxZI0I1I2I3A  B4:1muxZI0I1A2:1muxZk=0nMultiplexers/selectors (cont'd)n2:1 mux:Z = A'I0+ AI1n4:1 mux:Z = A'B'I0+ A'BI1+ AB'I2+ ABI3n8:1 mux:Z = A'B'C'I0+ A'B'CI1+ A'BC'I2+ A'BCI3+AB'C'I4+ AB'CI5+ ABC'I6+ ABCI7nIn general:Z = S(mkIk)qin minterm shorthand form for a 2n:1 MuxHow can we express the output in a general form, regardless of the # of inputs? First of all, n is the # of control wires. So there are total 2**n inputs. Here m_k is the k-th minterm from the control variables.10Gate level implementation of muxesn2:1 muxn4:1 mux\nAt the top left, an AND-OR realization of a 2:1 MUX is shown. What are the 2 data inputs and what is the control input?11control signals B and C simultaneously choose one of I0, I1, I2, I3 and one of I4, I5, I6, I7control signal A chooses which of theupper or lower mux's output to gate to Zalternativeimplementation\nCZA  B4:1mux2:1mux2:1mux2:1mux2:1muxI4I5I2I3I0I1I6I78:1muxCascading multiplexersnLarge multiplexers can be made by cascading smaller onesZI0I1I2I3AI4I5I6I7B  C4:1mux4:1mux2:1mux8:1mux\nYou can build a large scale MUX in two ways. One option is just to use a single conventional MUX for 2**n inputs and n control lines. Or you can combine small scale MUXs. This slide shows two cases of building an 8:1 MUX from small scale MUXs.12Multiplexers as general-purpose logicnA 2n:1 multiplexer can implement any function of n variablesqwith the variables used as control inputs andqthe data inputs tied to 0 or 1qin essence, a lookup tablenExample:qF(A,B,C) = m0 + m2 + m6 + m7= A'B'C' + A'BC' + ABC' + ABC=   A'B'C'(1) + A'B'C(0) + A'BC'(1) + A'BC(0) + AB'C'(0) + AB'C(0) + ABC'(1) + ABC(1)F = A'B'C'I0+ A'B'CI1+ A'BC'I2+ A'BCI3+ AB'C'I4+ AB'CI5+ ABC'I6+ ABCI7CAB01234567S28:1 MUXS1S0Z10100011FThis slide is very important. Actually a MUX can do more than just selection. Suppose each input wire (one of 2**n inputs) is fixed to either 0 or 1. Depending on the control inputs (here A,B,C), the corresponding bit will be popped up to F. This is kind of a lookup table.Now look at the system with a different viewpoint. Forget this is a MUX. Suppose A,B,C are the input variables of a logic function F. When will F be true? The reality is that a MUX can implement any function of n variables. Here is another example of implementing the same logic function in a simplified way. In this variation, one of the control variable is used as a data input of a 4:1 MUX. Now we have two control variables A and B. Meanwhile C becomes some of the data inputs. Overall, we have 4 cases instead 8 cases by considering F as a function of C13ABCF00010010010101101000101011011111C'C'01ABS1S0F01234:1 MUXC'C'01FCAB0123456710100011S28:1 MUXS1S0Multiplexers as general-purpose logic (cont’d)nA 2n-1:1 multiplexer can implement any function of n variablesqwith n-1 variables used as control inputs andqthe data inputs tied to the last variable or its complementnExample:qF(A,B,C) = m0 + m2 + m6 + m7= A'B'C' + A'BC' + ABC' + ABC= A'B'(C') + A'B(C') + AB'(0) + AB(1)14nGeneralizationnExample: G(A,B,C,D)can be realizedby an 8:1 MUXn-1 mux control variablessingle mux data variablefour possibleconfigurationsof truth tablerows can beexpressed asa function of In-1I0I1. . .In-2In-1F....00011....101010In-1In-1'1Multiplexers as general-purpose logic (cont’d)\nchoose A,B,C as control variablesCAB012345671D01D’DD’D’S28:1 MUXS1S0ABCDG000010001100100001110100001010011010111110001100101010010111110011101011101111101D01D'DD’D’Here is the generalized n-input logic function by a (n-1)-input MUX.Depending on the output of two cases of the singled-out variable, a different data input is attached to each minterm of the (n-1) input MUX. Reducing the MUX size is economical.151:2 Decoder:O0 = G •S’O1 = G •S 2:4 Decoder:    O0 = G •S1’ •S0’O1 = G •S1’ •S0O2 = G •S1  •S0’O3 = G •S1  •S03:8 Decoder:          O0 = G •S2’ •S1’ •S0’O1 = G •S2’ •S1’ •S0O2 = G •S2’ •S1  •S0’O3 = G •S2’ •S1  •S0O4 = G •S2  •S1’ •S0’O5 = G •S2  •S1’ •S0O6 = G •S2  •S1  •S0’O7 = G •S2  •S1  •S0Demultiplexers (DEMUXs)/decodersnDecoders/demultiplexers: general conceptqsingle data input, n control inputs, 2noutputsqcontrol inputs (called “selects” (S)) represent binary index of output to which the input is connectedqdata input usually called “enable” (G)\nThere is only one data input in DEMUXs, often denoted by G, which will be carried to one of the outputs. The control inputs are often denoted by S and the index of the control wires. Again, for n control inputs, we have 2**n outputs.16active-high enableactive-low enableactive-high enableactive-low enableO0GSO1O0\\GSO1\nS1O2O3O0GO1\nS0S1O2O3O0\\GO1\nS0Gate level implementation of demultiplexersn1:2 decodersn2:4 decoders\nThis slide shows a few DEMUXs implemented by logic gates. We can add two bubbles for each input. The reason for inserting two bubbles is to implement the DEMUX by NOR gates170A'B'C'D'E'1234567S23:8 DECS1S0AB0123S12:4 DECS0F012A'BC'DE'34567S23:8 DECS1S0\nECD0AB'C'D'E'1234567AB'CDECascading decodersn5:32 decoderq1 x 2:4 decoderq4 x 3:8 decoders\n3:8 DEC01234567ABCDEECDS2S1S0S23:8 DECS1S0By combining small scale decoders or demuxes, we can build a larger-scale demux.Here, we have 5 control lines (A,B,C,D,E) to route the enable line, F, to one of 32 output lines18demultiplexer generates appropriateminterm based on control signals(it \"decodes\" control signals)Demultiplexers as general-purpose logicnA n:2ndecoder can implement any function of n variablesqwith the variables used as control inputsqthe enable input is tied to 1 andqthe appropriate minterms summed to form the functionA'B'C'A'B'CA'BC'A'BCAB'C'AB'CABC'ABCCAB01234567S23:8 DECS1S0“1”Like a MUX, a DEMUX can also perform a logic function of n variables. Here n variables are used for the control wires of the DEMUX. Depending on the values of control wires, a specific minterm will be asserted. Then what we need to do is ORing the relevant minterms for each output function F.19F1F2F3Demultiplexers as general-purpose logic (cont’d)nF1 = A'BC'D + A'B'CD + ABCDnF2 = ABC'D' + ABCnF3 = (A' + B' + C' + D')\nAB0A'B'C'D'1A'B'C'D2A'B'CD'3A'B'CD4A'BC'D'5A'BC'D6A'BCD'7A'BCD8AB'C'D'9AB'C'D10AB'CD'11AB'CD12ABC'D'13ABC'D14ABCD'15ABCD4:16DECEnable\nCDBy using a single 4:16 DEMUX, we can implement three functions of 4 variables, with a few more gates.DEMUX is a minterm generator!20•   •   •inputsANDarray•   •   •outputsORarrayproducttermsProgrammable logic arrays (PLAs)nPre-fabricated building block of many AND/OR gatesqactually NOR or NANDq\"personalized\" by making/breaking connections among the gatesqprogrammable array block diagram for sum of products form\nA PLA is a general implementation of sum of products of a logic function. We first implement each product term (not necessarily minterm). Then the product terms will be Ored in the next stage. So we have two generic logic arrays. Programming means configuring connections in two arrays.Sum ofproducts21example:F0 = A  + B' C'F1 = A C'  +  A BF2 = B' C'  +  A BF3 = B' C  +  Apersonality matrix1 = uncomplemented in term0 = complemented in term–= does not participate1 = term connected to output0 = no connection to outputinput side:output side:productinputsoutputstermABCF0F1F2F3AB11–0110B'C–010001AC'1–00100B'C'–001010A1––1001reuse of termsEnabling conceptnShared product terms among outputs\nLet’s take some logic functions for example to illustrate how we can use an PLA for logic implementation. There are 4 functions of three input variables. To use an PLA systematically, it is good to write a personality matrix. The middle section indicates how input variables are combined in the AND array and the right section shows how those product terms are combined in the OR array.Before programmingnAll possible connections are available before \"programming\"qin reality, all AND and OR gates are NANDs\nWe have to look at two cross-connects: one is between inputs and AND gates and the other is between AND gates and OR gates. We can make or break connections in those two cross-connects.ABABC\n2223ABC\nF1F2F3F0ABB'CAC'B'C'AAfter programmingnUnwanted connections are \"blown\"qfuse (normally connected, break unwanted ones)qanti-fuse (normally disconnected, make wanted connections)\nThen we have to do programming, which is the process of enabling or disabling each cross-point. If fuses are used for each cross point, we break unwanted ones. If anti-fuses are used, we enable the wanted ones. nShort-hand notation so we don't have to draw all the wiresqxsignifies a connection is present and perpendicular signal is an input to gate\n24notation for implementingF0 = A B  +  A' B'F1 = C D'  +  C' D\nAB+A'B'CD'+C'DABA'B'CD'C'DABCDAlternate representation for high fan-in structures\nFor simplicity, let’s assume fuses for each crosspoint, denoted by x. Before programming, the PLA will look like the one on the left. After programming for the required functions, the PLA will become the one on the right. All the unwanted crosspoints are broken.25ABCF1F2F3F4F5F6000001100001010111010010111011010100100010111101010100110010100111110011A'B'C'A'B'CA'BC'A'BCAB'C'AB'CABC'ABCABC\nF1F2F3F4F5F6full decoder as for memory addressbits stored in memoryPLA examplenMultiple functions of A, B, CqF1 = A B CqF2 = A + B + CqF3 = A' B' C'qF4 = A' + B' + C'qF5 = A xor B xor CqF6 = A xnor B xnor C\nHere are the six functions of three variables.As there are three variables, total 8 minterms exist. Then all the relevant minterms of each function will be connected to its OR gate.26a given column of the OR array has access to only a subset of the possible product termsPALs and PLAsnProgrammable logic array (PLA)qunconstrained fully-general AND and OR arraysnProgrammable array logic (PAL)qconstrained topology of the OR arrayqfaster and smaller OR plane\nA little bit less programmable but faster version is PAL. In PALs, the cross-connects between AND gates and OR gates are already fixed; the transistor logic is much simpler. What we can control is the cross-connects between inputs and AND gates, denoted by x. So, there is less flexibility in PALs compared to PLAs.27minimized functions:W = A + BD + BCX = BC'Y = B + CZ = A'B'C'D + BCD + AD' + B'CD'ABCDWXYZ00000000000100010010001100110010010001100101111001101010011110111000100110011000101–––––11––––––PALs and PLAs: design examplenBCD to Gray code converter\nSuppose we have to design a BCD to GRAY code converter. And simplified functions are shown in the above. Unfortunately, there are no common product terms among outputs.28not a particularly goodcandidate for PLAimplementation since no terms are shared among outputshowever, much more compact and regular implementation when compared with discrete AND and OR gatesAB CDminimized functions:W = A + BD + BCX = B C'Y = B + CZ = A'B'C'D + BCD + AD' + B'CD'PALs and PLAs: design example (cont’d)nCode converter: programmed PLAABDBCBC'BCA'B'C'DBCDAD'BCD'WX YZHere, 4 functions are implemented by a single PLA. Total 10 product terms are needed to be represented. In this case, there is no common product term that can be shared by multiple outputs, which means PLA is not an attractive option.294product terms per each OR gateABDBC0BC'000BC00A'B'C'DBCDAD'B'CD'WXYZAB CDPALs and PLAs: (cont’d)nCode converter: programmed PAL\nLet’s consider a PAL where exactly 4 AND gatesare ORed for each function. Note that the maximum # of product terms of outputs is 4As there are 4 functions, total 16 AND gates are required. For some functions, they don’t need up to 4 product terms. Then, a FALSE term is connected to surplus AND gates. To make a false term, just leave all the fuses intact.Could be a limiting factor30WXYZBB\nBBBB\\BCCC\nCCAAADDD\\D\\DPALs and PLAs: design example (cont’d)nCode converter: NAND gate implementation of PAL and PLA\nAs we have seen before, an AND-OR combination is easily converted to NAND logic. Just add two bubbles (inverters) in the middle and push them to the opposite directions. So PALs and PLAs are actually implemented by NAND gates.31ActivitynMap the following functions to the PLA below:qW = AB + A’C’ + BC’qX = ABC + AB’ + A’BqY = ABC’ + BC + B’C’ABC\nWXY32Activity (cont’d)33Activity (cont’d)n9 terms won’t fit in a 7 term PLAqcan apply concensus theoremto W to simplify to:W = AB + A’C’n8 terms wont’ fit in a 7 term PLAqobserve that AB = ABC + ABC’qcan rewrite W to reuse terms:W = ABC + ABC’ + A’C’nNow it fitsqW = ABC + ABC’ + A’C’qX = ABC + AB’ + A’BqY = ABC’ + BC + B’C’nThis is called technology mappingqmanipulating logic functionsso that they can use available resourcesABCABC’A’C’AB’A’BBCB’C’ABC\nWXYLet’s look at the simplified structure of a ROM. A ROM is just like a look-up table whose structure is similar to that of a DEMUX. Actually, all the minterms are present in ROMs. Instead of the enable wire, the bits for outputs are programmed. When an address is coming in, its stored data (bits) should be brought up. An address to retrieve each stored word is equal to a minterm in the decoder.34decoder0n-1Address2   -1n01111word[i] = 0011word[j] = 1010bit lines (normally pulled to 1 through resistor –selectively connected to 0 by word line controlled switches)jiinternal organizationword lines (only one is active –decoder is just right for this)Read-only memories (ROMs)nTwo dimensional array of 1s and 0sqentry (row) is called a \"word\"qwidth of row = word-sizeqindex is called an \"address\"qaddress is inputqselected word is output35F0 = A' B' C  +  A B' C'  +  A B' CF1 = A' B' C  +  A' B C'  +  A B CF2 = A' B' C'  +  A' B' C  +  A B' C'F3 = A' B C  +  A B' C'  + A B C'\ntruth tableABCF0F1F2F300000100011110010010001100011001011101100011000011110100block diagramROM8 words x 4 bits/wordaddressoutputsABCF0F1F2F3ROMs and combinational logicnCombinational logic implementation (two-level canonical form) using a ROM\nSo, a number of functions can be implemented together by using a single ROM. Here, total 32 bits are stored and 4 bits constitute a word. Actually, we don’t need those boolean expressions. We just need to fill in the ROM by the truth table and that’s it.36ROM structurenSimilar to a PLA structure but with a fully decoded AND arrayqcompletely flexible OR array (unlike PAL)n address lines•   •   •inputsdecoder2nwordlines•   •   •outputsmemoryarray(2nwordsby m bits)m data linesA ROM is similar to a PLA, but for n inputs, there are always 2**n AND gates. Depending on the output values, what we need to do is to control transistors of crosspoints (or bits)By using ROMs, we can implement a number of functions quickly at the cost of large size (e.g. 2**n AND gates). Also, we cannot utilize DC terms. We can say that if we have to use many minterms, the ROM approach is the best. If there are many shared product terms among outputs, PLA may be good. If the number of product terms for each output is small, PAL may be the best approach37ROM vs. PLA/PALnROM approach advantageous whenqdesign time is short (no need to minimize output functions)qmost input combinations are needed (e.g., code converters)qlittle sharing of product terms among output functionsnROM problemsqsize doubles for each additional inputqcan't exploit don't caresnPLA approach advantageous whenqdesign tools are available for multi-output minimizationqthere are relatively few unique minterm combinationsqmany minterms are shared among the output functionsnPAL problemsqconstrained fan-ins on OR plane38Regular logic structures for two-level logicnROM –full AND plane, general OR planeqcheap (high-volume component)qcan implement any function of n inputsqmedium speednPAL –programmable AND plane, fixed OR planeqintermediate costqcan implement functions limited by number of termsqhigh speed (only one programmable plane that is much smaller than ROM's decoder)nPLA –programmable AND and OR planesqmost expensive (most complex in design, need more sophisticated tools)qcan implement any function up to a product term limitqslow (two programmable planes)This slide shows a pro-con list of ROM, PAL, PLA technologies. ROMs may be the cheapest due to mass production. In PALs, the OR array is fixed; it takes less time in the OR array. However, no shared product terms is supported in PALs. PLA is the most flexible and expensive option among logic implementation technologies.39Combinational logic technology summarynRandom (fixed) logicqSingle gates or in groupsqconversion to NAND-NAND and NOR-NOR networksqtransition from simple gates to more complex gate building blocksqreduced gate count, fan-ins, potentially fasterqmore levels, harder to designnTime response in combinational networksqgate delays and timing waveformsqhazards/glitches (what they are and why they happen)nRegular logicqmultiplexers/decodersqROMsqPLAs/PALsqadvantages/disadvantages of eachIn chapter 4, we looked at a few programmable structures that facilitate the implementations of two-level logic functions. Each structure has its own pros and cons."
    },
    {
        "document_id": "Lecture05_CombEx.pdf",
        "text": "1Chapter 5Case studies in combinational logic designNow we have gone through every part of combinational logic system design.In this chapter, the final chapter of combination logic, we will look at some examples and elaborate on the whole design process.© Copyright 2004, Gaetano Borriello and Randy H. Katz2Combinational logic design case studiesnGeneral design procedurenCase studiesqBCD to 7-segment display controllerqlogical function unitqprocess line controllerqcalendar subsystemnArithmetic circuitsqinteger representationsqaddition/subtractionqarithmetic/logic unitsI will talk about the steps of a general procedure to design a combinational logic system first and then take some examples.3General design procedure for combi. logic1.  Understand the problemqwhat is the circuit supposed to do?qwrite down inputs (data, control) and outputsqdraw block diagram or other picture2.  Formulate the problem using a suitable design representationqtruth table or waveform diagram are typicalqmay require encoding of symbolic inputs and outputs3.  Choose implementation targetqROM, PAL, PLAqmux, decoder and OR-gateqdiscrete gates (fixed logic)4.  Follow implementation procedureqK-maps for two-level, multi-levelqdesign CAD tools and hardware description language (e.g., Verilog)Typically, we have to separate the I/O variables and system internals to understand the problem. Step 2 is abstract representation while steps 3 and 4 are H/W implementation dependent4Tip: CAD tool’s typical functionalitiesnDesign entrynTruth table, schematic capture, HDLnSynthesis and optimizationnSimulationnPhysical designFirst of all, a user of a CAD tool should be able to specify the requirements of a logic circuit to be designed. The requirements can be expressed by a truth table or a graphical drawing, or a language.Synthesis usually refers to the process of translating designer’s requirements into a circuit graph.Physical design transforms the circuit graph into a layout (or blueprint) for fabrication 5BCD to 7–segmentcontrol signaldecoderc0  c1  c2  c3  c4  c5  c6\nA   B   C   DBCD to 7-segmentdisplay controllernUnderstanding the problemqinput is a 4 bit bcd digit (A, B, C, D)qoutput is the control signals for the display (7 outputs C0 –C6)nBlock diagramc1c5c2c4c6c0c3\nThe first case is to control or display one digit system whose input follows BCD coding.A digit can be represented by a combination of 7 segments. Depending on input variables, we have to turn on relevant pieces or segments.6ABCDC0C1C2C3C4C5C600001111110000101100000010110110100111111001010001100110101101101101101011111011111100001000111111110011110011101––––––––11–––––––––Formalize the problemnTruth tableqshow don't caresnChoose implementation targetqif ROM, we are doneqdon't cares imply PAL/PLAmay be attractivenFollow implementation procedureqminimization using K-mapsHow many input variables? And output variables?If we use ROM for the implementation technology, then the game is over. What we need to do is just to store 7 bit values for each minterm, total 2**4 cases. Even though we need to use only 10 minterms, we have to use 2**4 AND gates, whose size is much bigger than other technologies. So we choose PAL or PLA, where minimum # of product terms are desirable. As there are DC terms, we may be able to reduce the size of the system by minimization in two-level logic design.7C0 = A + B D + C + B' D'C1 = C' D' + C D + B'C2 = B + C' + DC3 = B' D' + C D' + B C' D + B' CC4 = B' D' + C D'C5 = A + C' D' + B D' + B C'C6 = A + C D' + B C' + B' CImplementation as minimized sum-of-productsn15 unique product terms when minimized individually1    0    X    10    1    X    1 1    1    X    X1    1    X    X DABC1    1    X    11    0    X    1 1    1    X    X1    0    X    X DABC0    1    X    10    1    X    1 1    0    X    X1    1    X    X DABC1    1    X    11    1    X    1 1    1    X    X0    1    X    X DABC1    0    X    10    1    X    0 1    0    X    X1    1    X    X DABC1    0    X    10    0    X    0 0    0    X    X1    1    X    X DABC1    1    X    10    1    X    1 0    0    X    X0    1    X    X DABCHere are the final two-level s-o-p forms for 7 output functions. After removing duplicate product terms, we have 15 different product terms to represent 7 outputs. We should note that the minimized form of each output may not lead to the globally minimum number of product terms. In this case, we have 15 product terms for 7 outputsC0C1C2C3C4C5C6\n7V -Combinational Logic Case Studies© Copyright 2004, Gaetano Borriello and Randy H. Katz8C0 = B C' D + C D + B' D' + B C D' + AC1 = B' D + C' D' + C D + B' D'C2 = B' D + B C' D + C' D' + C D + B C D'C3 = B C' D + B' D + B' D' + B C D'C4 = B' D' + B C D'C5 = B C' D + C' D' + A + B C D'C6 = B' C + B C' + B C D' + AC0 = A + B D + C + B' D'C1 = C' D' + C D + B'C2 = B + C' + DC3 = B' D' + C D' + B C' D + B' CC4 = B' D' + C D'C5 = A + C' D' + B D' + B C'C6 = A + C D' + B C' + B' CC2Implementation as minimized S-o-P (cont'd)nCan do betterq9 unique product terms (instead of 15)qshare terms among outputsqeach output not necessarily in minimized form1    1    X    11    1    X    1 1    1    X    X0    1    X    X DABC1    1    X    11    1    X    1 1    1    X    X0    1    X    X DABCC2\nLet’s look at C2 output variable. If we relax the minimization process of C2, we have more terms for C2 output. However, this less efficient minimization achieves sharing more product terms in the overall system (7 outputs). Note that the number of product terms of each output increases. Can we figure out this globally optimal minimization?9BC'B'CB'DBC'DC'D'CDB'D'ABCD'ABCD\nC0  C1  C2  C3  C4  C5  C6  C7PLA implementation\nSince there are up to 5 product terms for outputs, PAL may not be attractive. There are many common terms; so PLA is a good choice.Let’s consider PAL implementation whereup to 4 product terms can be ORed. Unfortunately, there are outputs that have 5 product terms. In that case, we have to resort to multi-level logic. You don’t need to do that; the CAD tool will do the job.10C0 = C3+ A' B X'+ A D YC1 = Y+ A' C5'+ C' D' C6C2 = C5+ A' B' D + A' C DC3= C4+ B D C5+ A' B' X'C4= D' Y+ A' C D'C5= C' C4+ A Y+ A' B XC6= A C4+ C C5 + C4'C5+ A' B' CX = C' + D'Y = B' C'PAL implem. vs. Discrete gate implementationnLimit of 4 product terms per outputqdecomposition of functions with larger number of termsqdo not share terms in PAL anyway(although there are some shared terms)\nnDecompose into multi-level logic (hopefully with CAD support)qfind common sub-expressions among functionsC2 = B + C' + DC2 = B' D + B C' D + C' D' + C D + B C D'C2 = B' D + B C' D + C' D' +WW= C D + B C D'need another input and another output11C0C1C2FunctionComments0001always 1001A + Blogical OR010(A • B)'logical NAND011A xor Blogical xor100A xnor Blogical xnor101A • Blogical AND110(A + B)'logical NOR1110always 03 control inputs: C0, C1, C22 data inputs: A, B1 output: FLogical function unitnMulti-purpose function blockq3 control inputs to specify operation to perform on operandsq2 data inputs for operandsq1 output of the same bit-width as operands\nThe next example is the very versatile functional block, which performs various functions. There are three control variables whose values determine the output of the function of two data input variables.12Formalize the problemC0C1C2ABF000001000011000101000111001000001011001101001111010001010011010101010110011000011011011101011110100001100010100100100111101000101010101100101111110001110010110100110110111000111010111100111110choose implementation technology5-variable K-map to discrete gatesmultiplexer implementation10ABABAB\nC2C0C101234567S28:1 MUXS1S0FIn order to realize the multi-purpose function, we combine discrete gates and an 8:1 MUX.Production line controlnRods of varying length (+/-10%) travel on conveyor beltqmechanical arm pushes rods within spec (+/-5%) to one sideqsecond arm pushes rods too long to other sideqrods that are too short stay on beltq3 light barriers (light source + photocell) as sensorsqdesign combinational logic to activate the armsnUnderstanding the problemqinputs are three sensorsqoutputs are two arm control signalsqassume sensor reads \"1\" when trippedn\"0\" otherwise (if nothing to detect)qcall sensors A, B, CThe next case study to look at is a product line control (PLC) system that manufactures a rod. What we need to do is to check whether each rod’s length is within a certain bound (±5% of the spec). In order to examine the length of each rod, we use three sensors to measure the rod. If the rod is within spec, the rod will be pushed to one side. If the rod is too long, it will be pushed to the other side.Otherwise, it will stay on the belt. 1314Sketch of problemnPosition of sensorsqA to B distance = specification –5%qA to C distance = specification + 5%WithinSpecTooShortTooLongA\nBCspec-5% spec+ 5%What if we don’t have sensor A? We cannot know the reference point or time at which we can  measure the length of each rod. So when sensor A becomes 1, we should check sensors B and C as well to measure the length of the moving rod.15logic implementation now straightforwardjust use three 3-input AND gates\"too short\" = AB'C'(only first sensor tripped)\"in spec\" = A B C'(first two sensors tripped)\"too long\" = A B C(all three sensors tripped)ABCFunction000do nothing001do nothing010do nothing011do nothing100too short101don't care110in spec111too longFormalize the problemnTruth tableqshow don't cares\nIf A is zero, that means there is no rod to inspect. So all the outputs are 0.Otherwise, there is a rod. Then we have to check sensors B and C. Note that 101 is a DC term. 110 means that the rod is of standard length. The textbook says the top 4 minterms (000 –011) are also DC terms, but that may cause energy waste.16Steps 3 and 4nChoose implementation technologyqThe actual logic is so simple; use fixed logic gatesnFollow implementation procedureqOne minterm for each outputSo the truth table is done. As the overall logic is so simple. Maybe the random logic approach is the best. There are three outputs, each of which has only one minterm17integer number_of_days ( month, leap_year_flag) {switch (month) {case  1: return (31);case  2: if (leap_year_flag == 1)then return (29)else return (28);case  3: return (31);case  4: return (30);case  5: return (31);case  6: return (30);case  7: return (31);case  8: return (31);case  9: return (30);case 10: return (31);case 11: return (30);case 12: return (31);default: return (0);}}Calendar subsystemnDetermine number of days in a month (to control watch display)qused in controlling the display of a wrist-watch LCD screenqinputs: month, leap year flagqoutputs: number of daysnUse software implementationto help understand the problem\nFor the next example, we revisit the number of days per month problem. But this time, we will follow the general procedure to design the system. Then we will look at the details of the leap year flag.18leapmonth\n28293031monthleap282930310000–––––0001–00010010010000010101000011–00010100–00100101–00010110–00100111–00011000–00011001–00101010–00011011–00101100–00011101–––––111––––––Formalize the problem\nAgain 4 wires for the input of month and one wire for leap year and 4 wires for the output (note that only two wires are needed for output at minimum)nEncoding:qbinary number for month: 4 bitsq4 wires for 28, 29, 30, and 31one-hot –only one true at any timenBlock diagram:19monthleap282930310000–––––0001–00010010010000010101000011–00010100–00100101–00010110–00100111–00011000–00011001–00101010–00011011–00101100–00011101–––––111––––––Choose implem. target and perform mappingnDiscrete gatesq28 = q29 =q30 = q31 = nCan translate to S-o-P or P-o-Sm8’ m4’ m2 m1’ leap’m8’ m4’ m2 m1’ leapm8’ m4 m1’ + m8 m1m8’ m1 + m8 m1’If we are to use discrete logic gates such as AND or OR, SoP or PoS will be enough.Just investigate all the elements of the On-set, and make product terms and then combine them by OR gates in SoP case. From now on we will look at the leap year flag. How can we know that a year is a leap year or not?20Leap year flagnDetermine value of leap year flag given the yearqFor years after 1582 (Gregorian calendar reformation), qleap years are all the years divisible by 4, qexcept that years divisible by 100 are not leap years, qbut years divisible by 400 are leap years. nEncoding the year:qbinary –easy for divisible by 4, 2006:1111101010but difficult for 100 and 400 (not powers of 2)qBCD –easy for 100, 2006: 0010 0000 0000 0110but more difficult for 4, what about 400?nParts:qconstruct a circuit that determines if the year is divisible by 4qconstruct a circuit that determines if the year is divisible by 100qconstruct a circuit that determines if the year is divisible by 400qcombine the results of the previous three steps to yield the leap year flagPope Gregory I set up the current leap year system in 1582. There are only three simple rules that decides the number of days in Feb. Note that an encoding scheme can affect the system design fundamentally.21Activity: divisible-by-4 circuitnBCD coded year qYM8 YM4 YM2 YM1 –YH8 YH4 YH2 YH1 –YT8 YT4 YT2 YT1 –YO8 YO4 YO2 YO1nOnly need to look at low-order two digits of the yearall years ending in 00, 04, 08, 12, 16, 20, etc. are divisible by 4qif tens digit is even, then divisible by 4 if ones digit is 0, 4, or 8qif tens digit is odd, then divisible by 4 if the ones digit is 2 or 6.  nTranslates into the following Boolean expression(where YT1 is the year's tens digit low-order bit, YO8 is the high-order bit of year's ones digit, etc.):YT1’ (YO8’ YO4’ YO2’ YO1’ + YO8’ YO4 YO2’ YO1’ + YO8 YO4’ YO2’ YO1’ ) + YT1 (YO8’ YO4’ YO2 YO1’ + YO8’ YO4 YO2 YO1’ )nDigits with values of 10 to 15 will never occur, simplify further to yield: D4 = YT1’ YO2’ YO1’ + YT1 YO2 YO1’YM stands for year millennium and the each digit of the year will be represented as the binary value by BCD encoding. So we need 4 wires for each digit of the year, total 16 wires. D4 is the flag that indicates whether the year of input is divisible by 422Divisible-by-100 and divisible-by-400 circuitsnDivisible-by-100 just requires checking that all bits of two low-order digits are all 0:D100 = YT8’ YT4’ YT2’ YT1’   •   YO8’ YO4’ YO2’ YO1’ nDivisible-by-400 combines the divisible-by-4 (applied to the thousands and hundreds digits) and divisible-by-100 circuitsD400 = (YM1’ YH2’ YH1’ + YM1 YH2 YH1’) • (YT8’ YT4’ YT2’ YT1’ •  YO8’ YO4’ YO2’ YO1’ )With BCD encoding, it is easy to check whether the year of input is divisible by 100 and 400. A year is divided by 100 without remainder if the lowest two digits are 00A year is divided by 400 without residue if the lowest two digits are 00 and the highest two digits are divided by 4.23Combining to determine leap year flagnLabel results of previous three circuits: D4, D100, and D400leap_year_flag= D4 • D100’ + D4 • D400= D4 • D100’ + D400Now we have three (internal) variables, each of which indicates whether the year is divisible by 4, 100, 400, respectively. The final leap year flag should be true when D4 is true. But if D100 is true than the flag is false. Note that the flag is also true when D4 and D400 is true24Implementation of leap year flag\n25Arithmetic circuitsnExcellent examples of combinational logic designnTime vs. space trade-offsqdoing things fast may require more logic and thus more spaceqexample: carry lookahead logicnArithmetic and logic unitsqgeneral-purpose building blocksqcritical components of processor datapathsqused within most computer instructionsNow we are going to see a little bit different logic system, whose purpose is to perform a mathematical function. We will look at adders mostly.In most of engineering systems, there is always a trade-off. We cannot have all the best features in a single system. As mentioned earlier, if we use a number of gates in parallel (say, two-level SoP canonical forms), we can minimize the delay of the system. If we want to reduce the number of gates, there will be multiple levels, which increases delay. We will revisit this issue by going over multiple variations of adder systemsNumber systemsnRepresentation of positive numbers is the same in most systems nMajor differences are in how negative numbers are represented nRepresentation of negative numbers come in three major schemesqsign and magnitudeq1s complementq2s complementnAssumptionsqwe'll assume a 4 bit machine word q16 different values can be represented qroughly half are positive, half are negativeTo design arithmetic functions, we have to understand how a number is represented in computers.  We talked about binary coding, BCD coding and so on. Here we choose the binary coding as the basic representation system but will focus on how negative numbers  are expressed.For the purpose of illustration, we consider the case of using 4 wires to represent a digit (positive and negative and zero).26270000\n011100111011111111101101110010101001100001100101010000100001+0+1+2+3+4+5+6+7–0–1–2–3–4–5–6–70100 = +41100 = –4Sign and magnitudenOne bit dedicate to sign (positive or negative)qsign: 0 = positive (or zero), 1 = negativenRest represent the absolute value or magnitudeqthree low order bits: 0 (000) thru 7 (111)nRange for n bitsq±( 2n–1–1)  (two representations for 0)nCumbersome addition/subtraction qmust compare magnitudesto determine sign of resultThe first encoding scheme is sign and magnitude; one bit is dedicated to the sign of the number and the rest of the bits represents the absolute value of the number |x|. If we use 4 bits total, the MSB is the sign + or -, and the other three bits represent the magnitude from 0 to 7. The problem is that when adding or subtracting numbers, we have to check the sign of the results.282=  100001=  000012   –1=    11117=    01111000   =  –7 in 1s complement form441s complementnIf N is a positive number, then the negative of N (or its 1s complement) is N' = (2n –1) –Nqexample: 1s complement of 7\nqshortcut: simply compute bit-wise complement ( 0111 -> 1000 )To remedy the sign-magnitude encoding problem, 1s complement is introduced. Here, a negative of N (which is –N) is denoted by N’ and is expressed by (2n-1)-N.The 1stbit implicitly says the sign of the number. The merit of this encoding scheme is that subtraction becomes easier.290000\n011100111011111111101101110010101001100001100101010000100001+0+1+2+3+4+5+6+7–7–6–5–4–3–2–1–00 100 = + 41 011 = –41s complement (cont'd)\nThen, subtraction can be easily performed. To compute A-B, just calculate 1s complement of B and then add it to A.  Actually this works only when B >= A. Look at the range from -7 to +7 and note that there are two kinds of 0s.nSubtraction implemented by 1s complement and then additionnTwo representations of 0qcauses some complexities in additionnHigh-order bit can act as sign bitnCarry should be added to the sum300 100 = + 41 100 = –4+0+1+2+3+4+5+6+7–8–7–6–5–4–3–2–10000\n0111001110111111111011011100101010011000011001010100001000012s complementn1s complement with negative numbers shifted one position clockwiseqonly one representation for 0 qone more negative numberthan positive numbersqhigh-order bit can act as sign bit2s compliment enhances the 1s complement encoding, it can represent up to -8 as shown in the above.312=100007= 01111001  = repr. of –742=10000–7=10010111  = repr. of 74subtractsubtract2s complement (cont’d)nIf N is a positive number, then the negative of N (or its 2s complement) is N* = 2n–Nqexample: 2s complement of 7qexample: 2s complement of –7\nqshortcut: 2s complement = bit-wise complement + 1n0111 -> 1000 + 1 -> 1001  (representation of -7)n1001 -> 0110 + 1 -> 0111  (representation of 7)Likewise, the 2s compliment of a positive number N is denoted by N*. If you want to make a 2s complement in case of 4 wires, just subtract the number from 2**4. Another simple way to calculate 2s complements is to invert all the bits and add 1. 324+ 37010000110111–4+ (–3)–711001101110014–310100110110001–4+ 3–11100001111112s complement addition and subtractionnSimple addition and subtractionqsimple scheme makes 2s complement the virtually unanimous choice for integer number systems in computers\nLet’s see how we can add or subtract the numbers encoded by 2s complement. Now subtraction is not so different from addition. Just make 2s complement and add it.33Why can the carry-out be ignored?nCan't ignore it completelyqneeded to check for overflow (see next two slides)nWhen there is no overflow, carry-out may be true but can be ignored–M + N when N > M:M*  +  N  =  (2n–M)  +  N  =  2n+  (N –M)ignoring carry-out is just like subtracting 2n–M + –N where N + M £2n-1(–M) + (–N) = M* +  N* = (2n–M) + (2n–N)   = 2n–(M + N)  +  2nignoring the carry, it is just the 2s complement representation for –(M + N)So far, we didn’t pay attention to the carry. We will first look at the cases where carry-outs can be ignored. Let M be the positive number to be converted by 2s complement. M* denotes 2s complement of M, which is 2n-M.There are two kinds of overflows in 2s complement arithmetic. In this case, the carry-out should not be ignored. The upper bound in 4 bits is +7; so when the sum exceeds this bound, there will be an overflow. Likewise, the lower bound is -8; so when the sum goes below -8, there is an overflow, which is also called underflow. Anyway, in these overflow cases, the adding system should report the error.345 + 3 = –8–7 –2 = +7+0+1+2+3+4+5+6+7–8–7–6–5–4–3–2–10000\n011100111011111111101101110010101001100001100101010000100001+0+1+2+3+4+5+6+7–8–7–6–5–4–3–2–10000\n011100111011111111101101110010101001100001100101010000100001Overflow in 2s complement addition / subtractionnOverflow conditionsqadd two positive numbers to get a negative numberqadd two negative numbers to get a positive number3553–80  11  10 1 0 10 0 1 11 0 0 0–7–271  00  01 0 0 11 1 1 01 0 1 1 15270  00  00 1 0 10 0 1 00 1 1 1–3–5–81  11  11 1 0 11 0 1 11 1 0 0 0overflowoverflowno overflowno overflowOverflow conditionsnOverflow when carry into sign bit position is not equal to carry-out\nThe numbers in blue indicate carries into the next higher-order bits in calculation.The condition to check overflow is to compare two highest carries in addition. If they are different, then it is an overflow.36AiBiSumCout0000011010101101AiBiCinSumCout0000000110010100110110010101011100111111Circuits for binary additionnHalf adder (add 2 1-bit numbers)qSum = Ai' Bi + Ai Bi' = Ai xor BiqCout = Ai BinFull adder (carry-in to cascade for multi-bit adders)qSum = Ci xor A xor BqCout = B Ci  +  A Ci  +  A B = Ci (A + B) + A B\nNow we get familiar with 2s complement. Let’s design a circuit that adds two binary numbers. First of all, let’s start with a 1 bit adder. Ai and Bi are i-th bits of two binary numbers, A and B, respectively. On the left, there is a truth table for a half adder; on the right, a truth table for a full adder which also considers the carry-in from the lower-order bits.37ABCA+B(A+B)C0000000100010100111110010101111101011111(A or B)C vs. (A xor B)CnThey are not equivalent but AB+(A+B)C = AB+(AÅB)C\nBefore going to the next step, let’s see the relation between two boolean expressions.ABCAÅB(AÅB)C0000000100010100111110010101111100011100(A or B)C is not equal to (A xor B)C. but when we add AB product term, they are equivalent.38Cout = A B + Cin (A xor B) = A B + Cin (A or B)ABCinSAABBCinCout\nABA xor BCinA xor Bxor CinHalfAdderSumCoutCin(A xor B)A BCoutHalfAdderSumCoutFull adder implementations\nAt the top, there is a fixed logic implementation of a full adder. If we use two half-adder modules to construct the full-adder system instead of using random logic, we can reduce the number of gates.nStandard approachq6 gatesq2 XORs, 2 ANDs, 2 ORsnAlternative implementationq5 gatesqhalf adder is an XOR gate and AND gateq2 XORs, 2 ANDs, 1 ORNow we have a full adder for one bit addition. Then what we want to do is addition/subtraction of two 4bit-numbers. Addition is easy. Recall that 2s complement of a number is its inverted form+1. So we can use the same adding function to perform subtraction too. For subtraction, we just enable the control input.39ABCoutSumCin01Add'SubtractA0B0B0'Sel\nOverflowABCoutSumCinA1B1B1'SelABCoutSumCinA2B2B2'Sel010101ABCoutSumCinA3B3B3'Sel\nS3S2S1S0Adder/subtractornUse an adder to do subtraction thanks to 2s complement representationqA –B  =   A + (–B)   =   A + B' + 1qcontrol signal selects B or 2s complement of BAABBCinCout@0@0@0@0@N@1@1@N+1@N+2latearrivingsignaltwo gate delaysto compute Cout4 stageadderA0B00S0 @2A1B1C1 @2S1 @3A2B2C2 @4S2 @5A3B3C3 @6S3 @7Cout @8Ripple-carry addersnCritical delayqthe propagation of carry from low to high order stages\nThe next advanced adder is a ripple-carry adder. What is the problem of the full adder in the previous slide? When we consider data bits, they are coming in parallel at the same time. However, carries should be cascaded with delays proportional to the bit positions. On the left, Cin comes at time N, then Cout will be valid at time N+2 (each one-bit adder incurs 2 gate delays)1111+0001\n4041\nRipple-carry adders (cont’d)nCritical delayqthe propagation of carry from low to high order stagesq1111 + 0001 is the worst case additionqcarry must propagate through all bits\nThis slide shows a waveform of a 4 bit adder. Suppose we add 1111 and 0001, the carry will propagate from the LSB all the way through to the final carry-out.42Carry-lookahead logicnCarry generate:  Gi = Ai Biqmust generate carry when A = B = 1nCarry propagate:  Pi = Ai xor Biqcarry-in will equal carry-out herenSum and Cout can be re-expressed in terms of generate/propagate:qSi= Ai xor Bi xor Ci= Pi xor CiqCi+1= Ai Bi + Ai Ci + Bi Ci= Ai Bi + Ci (Ai + Bi)= Ai Bi + Ci (Ai xor Bi)= Gi + Ci PiInstead of awaiting the carry from the lower-order bits, we can process the carry in advance. How?In order to do so, the carry should be derived from the lower-order data bits directly. First of all, let’s look at two new functions: Gi and Pi. Then Si and Ci+1can be rewritten as shown in the above. Actually, those imply two cases. When Gi is true, there is always a carry-out. If Pi is true, a carry-out depends on a carry-in.43Carry-lookahead logic (cont’d)nRe-express the carry logic as follows:qC1 = G0 + P0 C0qC2 = G1 + P1 C1 = G1 + P1 G0 + P1 P0 C0qC3 = G2 + P2 C2 = G2 + P2 G1 + P2 P1 G0 + P2 P1 P0 C0qC4 = G3 + P3 C3 = G3 + P3 G2 + P3 P2 G1 + P3 P2 P1 G0+ P3 P2 P1 P0 C0nEach of the carry equations can be implemented with two-level logicqall inputs are now directly derived from data inputs and not from intermediate carriesqthis allows computation of all sum outputs to proceed in parallelThen all the carries are calculated by the expanding Pi and Gi as shown in the above, which is called the carry-lookahead logic. Note that all carries are now just two-level logic functions. So here is the bottom line: there is a tradeoff between the number of gates and the delay.44G3C0C0C0C0P0P0P0P0G0G0G0G0C1 @ 3P1P1P1P1P1P1G1G1G1C2  @ 3P2P2P2P2P2P2G2G2C3 @ 3P3P3P3P3C4 @ 3Pi @ 1 gate delayCiSi @ 2 gate delaysBiAiGi @ 1 gate delayincreasingly complexlogic for carriesCarry-lookahead (CLA) implementationnAdder with propagate and generate outputs\nThis slide shows how 4 carries are implemented in two level fixed logic based on Pi and Gi. As Pi and Gi take only one gate delay, the final carries take maximum 3 gate delays.on the left, there is the original full adder, which takes a long time to finish addition. On the right, there is the carry lookahead adder. The two level logic functions for carries are not shown. Each box is the one-bit adder module. Overall, by using a lot of gates for CLA in the previous slide, we can reduce the delay of the addition process.45A0B00S0 @2A1B1C1 @2S1 @3A2B2C2 @4S2 @5A3B3C3 @6S3 @7Cout @8A0B00S0 @2A1B1C1 @3S1 @4A2B2C2 @3S2 @4A3B3C3 @3S3 @4C4 @3C4 @3CLA implementation (cont’d)nCarry-lookahead logic generates individual carriesqsums computed much more quickly in parallelqhowever, cost of carry logic increases with more stagesIf we add 16bit long numbers, we have to use 4 4bit CLA adder modules. Each module adds 4 bits. Here Ci at the bottom box is the carry from the i-th 4bit CLA adder module. Pi and Gi in blue color are the same functions in the previous example. While Pi and Gi at the bottom unit give info about the carries between the 4bit CLA modules, which is more complicated.46Lookahead Carry UnitC0P0G0P1G1P2G2P3G3C3C2C1C0P3-0G3-0C4@3@2@4@3@2@5@3@2@5@3@2@5@5@3@0C16A[15-12]B[15-12]C12S[15-12]A[11-8]B[11-8]C8S[11-8]A[7-4]B[7-4]C4S[7-4]@7@8@8A[3-0]B[3-0]C0S[3-0]@0@4444PG4-bit Adder444PG4-bit Adder444PG4-bit Adder444PG4-bit Adder16bit CLA adder with cascaded carry-lookahead logicnCarry-lookahead (CLA) adderq4 four-bit adders with internal carry lookaheadqsecond level carry lookahead unit extends lookahead to 16 bitsG= G3 + P3 G2 + P3 P2 G1 + P3 P2 P1 G0P= P3 P2 P1 P0\nC1 = G0 + P0 C0C2 = G1 + P1 G0 + P1 P0 C0The next version, a carry-select adder, achieves even lower delay by redundant h/w. Note that the carry between 4bit CLA adders is either 0 or 1. We use two adder modules for high 4 bit of the 8-bit adder system. So we performaddition for both cases and then the carry from the lower 4bit CLA module will perform selection (MUX). 474-Bit Adder[3:0]C0C44-bit adder[7:4]1C80C8five2:1 mux01010101adder lowadderhigh\n014-bit adder[7:4]\nC8S7S6S5S4S3S2S1S0Carry-select addernRedundant hardware to make carry calculation go fasterqcompute two high-order sums in parallel while waiting for carry-inqone assuming carry-in is 0 and another assuming carry-in is 1qselect correct result once carry-in is finally computed\n@4@3@5An ALU is a key subsystem of computers that performs logic and arithmetic functions. There are one high level control input M, and two lower level selection inputs S1 and S0. Here Ci is the carry value which is useful only for some arithmetic functions. 48logical and arithmetic operationsnot all operations appear useful, but \"fall out\" of internal logicS10011S00101FunctionFi = AiFi = not AiFi = Ai xor BiFi = Ai xnor BiCommentinput Ai transferred to outputcomplement of Ai transferred to outputcompute XOR of Ai, Bicompute XNOR of Ai, BiM = 0, logical bitwise operationsM = 1, C0 = 0, arithmetic operations00110101F = AF = not AF = A plus BF = (not A) plus Binput A passed to outputcomplement of A passed to outputsum of A and Bsum of B and complement of AM = 1, C0 = 1, arithmetic operations00110101F = A plus 1F = (not A) plus 1F = A plus B plus 1F = (not A) plus B plus 1increment Atwos complement of Aincrement sum of A and BB minus AArithmetic logic unit (ALU) design specification49M0\n1\n1S1001100110011S0010101010101CiXXXXXXXXXXXX000000000000111111111111Ai0101001100110101001100110 10100110011BiXXXX01010101XXXX01010101XXXX01010101Fi011001101001011001101001100110010110Ci+1XXXXXXXXXXXXXXXX00010100011001111101Arithmetic logic unit (ALU) design (cont’d)nSample ALU –truth tableFirst of all, there are three control inputs, three data inputs, and two data outputs.If M is 0, Ci is a DC term. Sometimes, Bi is also a DC term when only the 1stinput, Ai, matters nSample ALU –multi-level discrete gate logic implementation\n50Total 12 gates + 5 inverters\\S1\\Bi[35][35]MMMS1Bi[33][33][33][33]S0Ai[30][30][30][30][30]CiCiCiCiCo\\Co\\Co\\Co\\[30]\\[35]FiALU design (cont’d)\nIf we implement the truth table in the previous slide by a random logic with some minimization techniques, we can get the above multi-level logic system. Don’t worry; there are six variables. Humans are not supposed to do that. This result comes from a CAD tool. Numbers in [] are internal wires.51Summary for examples of combinational logicnCombinational logic design processqformalize problem: encodings, truth-table, equationsqchoose implementation technology (ROM, PAL, PLA, discrete gates)qimplement by following the design procedure for that technologynBinary number representationqpositive numbers the sameqdifference is in how negative numbers are representedq2s complement easiest to handle: one representation for zero, slightly complicated complementation, simple additionnCircuits for binary additionqbasic half-adder and full-adderqcarry lookahead logicqcarry-selectnALU Designqspecification, implementationWe looked at the design process of several combinational logic circuits and then reviewed how binary numbers are represented. Arithmetic functions are also discussed."
    },
    {
        "document_id": "Lecture06_Seq.pdf",
        "text": "1Chapter 6.Sequential logic designThis is the beginning of the second part of this course, sequential logic.\n© Copyright 2004, Gaetano Borriello and Randy H. Katz2Sequential logicnSequential circuitsqsimple circuits with feedbackqlatchesqedge-triggered flip-flopsnBasic registersqshift registersqsimple countersAgain, sequential logic circuits are quite different from combinational logic. In general, sequential systems are more difficult to design. We will discuss some basic issues in the sequential logic systems in this chapter.3C1C2C3comparatorvalueequalmultiplexerreset\nopen/closednewequalmux controlclockcomb. logicstateSequential logic circuits (SLCs)nCircuits with feedbackqoutputs = f(inputs, past inputs, past outputs)qbasis for building \"memory\" into logic circuitsqdoor combination lock is an example of a sequential circuitnstate is memorynstate is an \"output\" and an \"input\" to combinational logicncombination storage elements are also memory\nIn most sequential logic circuits (SLCs), there are storage parts or memory elements. Recall that in the door lock system, three numbers should be stored and compared. What is the key element here? \"remember\"\"load\"\"data\"\"stored value\"Let’s consider a simple memory element first. What if we place two inverters before a stored value and suppose the stored value is 1. Note that there is a feedback from the stored value to the first inverter. Another more sophisticated option is to have a selection function between a stored value and a new value. If “load” is enabled, the new “data” will be put into the stored value.4nTwo inverters form a static memory cellqwill hold value as long as it has power appliednHow to get a new value into the memory cell?qselectively break feedback pathqload new value into cell\n\"0\"\"1\"\"stored value\"Simplest circuits with feedback5\nRSQQ'\nRSQ\nR'S'Q\nQQ'S'R'Memory with cross-coupled gates\nLet’s consider this feedback in the cases of cross-connectivity between other gate types. With Nor or Nand gates, we can have more control inputs. R and S denote reset and set inputs, respectively. Q is the output value of interest and its inverse is denoted by Q’. For a NOR gate, think of a case when a single input can determine the output of the gate. Suppose R is 1, which makes Q 0. Basically, we assume R and S are opposite for update.Q'nCross-coupled NOR gates (R-S Latch)qsimilar to inverter pair, with capability to force output to 0 (reset=1) or 1 (set=1)\nnCross-coupled NAND gatesqsimilar to inverter pair, with capability to force output to 0 (R’=0) or 1 (S’=0)Q'6\nQ(t+D)RSQ(t)SRQ(t)Q(t+D)000000110100011010011011110X111Xholdresetsetnot allowedcharacteristic equationQ(t+D) = S + R’ Q(t)R-S latch analysisnBreak feedback path\nRSQQ'0010X1X1Q(t)RSTo analyze the timing, let’s assume the feedback loop is cut off. That is, consider Q(t) and Q(t+ ∆) separately. Here ∆ is the delay incurred by the latch. When you look at the truth table, you can notice something different. What is it? 6The problem happens when R=S=1. Are Q and Q’ just 0s? The more significant problem arises when R=S=1 and then R=S=0, which will yield an oscillation as follows. Q and Q’ will be 1 together. But then Q and Q’ should be changed to 0 again. Then this cycle continues.7\nResetHoldSetSetResetRaceRSQ\\Q100Timing behavior\nRSQQ'\nIf R=1 and S=0, Q is 0 and Q’ is 1 (recall the meaning of reset R). If R=0 and S=1, Q is 1. What if R=S=0, then Q and Q’ will remain with the previous values.8R’S’QQ'Activity: R-S latch using NAND gates\ncharacteristic equationQ(t+D) = S + R’ Q(t)\nR’S’Q(t)\n0010X1X1Q(t)RSSRS’ R’Q(t)Q(t+D)00110000111101100001101010010110011111000X11001Xholdresetsetnot allowed\nThe next version is a gated R-S latch. In the gated (level-sensitive) R-S latch, the R-S values are handled cautiously. When enable’ is high, then R and S are always zeroes (there is no glitch or fluctuation in R and S). So R’ and S’ are meaningful only when enable’ is low. This waveform shows when enable is high and S is set (or S’ is low), Q will become true.9\nenable’S'Q'QR'RSGated R-S latchnEnable controls when R and S inputs matterqotherwise, the slightest glitch on R or S could cause change in value stored\nSetResetS'R'enable’QQ'10010periodduty cycle (in this case, 50%)ClocksnUsed to keep timeqwait long enough for inputs (R' and S') to settleqthen allow to have effect on value storednClocks are regular periodic signalsqperiod (time between ticks)qduty-cycle (time clock is high between ticks -expressed as % of period)A clock is an important element in sequential circuits. The enable signal in the previous slide serves as kind of a clock. Once enable is asserted, it should remain high until the input stimulates the output fully. Normally, a clock is periodically alternating between high and low. The beginning of each period is called a clock tick. And the duty cycle is defined as the ratio of High voltage interval to the period.11Clocks (cont’d)nControlling an R-S latch with a clockqChange R and S while clock’ is 1 (inject new input)nonly have half of clock period for signal changes to propagateqKeep R and S stable while clock’ is 0 (allowing R and S to pass)nsignals must be stable for the other half of clock period\nclock’S’Q’QR’RSclock’R’  and  S’changingstablechangingstablestableLet’s control the gated  (or level-sensitive) R-S latch with a clock. While clock’ is 0, R’ and S’ should sustain their values which will update Q and Q’ during that interval. While clock’ is high, R’ and S’ can be changed to a new value (for next operation); in the meantime, Q and Q’ will not change since R and S are 00.12Master-slave structurenBreak flow by alternating clocksquse positive clock to latch inputs into one R-S latchquse negative clock to change outputs with another R-S latchnView pair as one basic unitqmaster-slave flip-flopqtwice as much logicqoutput changes a few gate delays after the falling edge of clockmaster stageslave stagePP’CLKRSQQ’RSQQ’RS13\nSet1s catchSRCLKPP’QQ’ResetMasterOutputsSlaveOutputsThe 1s catching problemnIn first R-S stage of master-slave FFq0-1-0 glitch on R or S while clock is high is \"caught\" by master stageqleads to constraints on logic to be hazard-freemaster stageslave stagePP’CLKRSQQ’RSQQ’RSWhat would be the problem of the inverted clock signals for the pair of R-S latches? While the clock is high, suppose there is a glitch is in the very first S (0-1-0), P and P’ will change, which in turn will affect the slave latch when the clock becomes low. This is called the 1s catching problem.To eliminate the 1s catching problem, we have to make S and R have opposite values; so we use the complementary values from the same input, which is called D flip-flop. D is an abbreviation for data. So R and S can be either 01 and 10 only. Now we cannot use 00 to maintain the same value in the latch. How many gates here? Each R-S latch has two NOR gates.1410 gatesD flip-flopnMake S and R complements of each otherqeliminates 1s catching problemqcan't just hold previous value(must have new value ready every clock period)qvalue of D just before clock goes low is what is stored in flip-flopnnegative edge-triggered DQQ’master stageslave stagePP’CLKRSQQ’RSQQ’The other realization to solve the 1s catching problem is to use a clock edge to trigger the change of the flip-flop’s value. While the clock is high, the second top NOR and the second bottom NOR gates will be 0, which keeps the old values of Q and Q’15\nQ\nDClk=1RS0D’0D’D\nQ’\nnegative edge-triggered D flip-flop (D-FF)4-5 gate delaysmust respect setup and hold time constraints to successfullycapture inputcharacteristic equationQ(t+1) = Dholds D’ whenclock goes low\nholds D whenclock goes low(Negative) Edge-triggered D flip-flops (FFs)nMore efficient solution: only 6 gatesqsensitive to inputs only near edge of clock signal (not while high)If clock goes from 1 to 0, initially S and R are 0. Then, depending on D’s value, S or R will be changed, which in turn will set or reset Q. The numbers in blue shows the case when D is 1. After that, D’s change makes no effect. E.g. new D is 0 now, D (second bottom NOR) was 1, D’(bottom) is 0. So D (top) is still 1; R and S are not changed.16\nQ\nDClk=0RSDD’D’D’D\nwhen clock goes high-to-lowdata is latchedwhen clock is lowdata is heldNegative Edge-triggered D flip-flops (cont’d)\nQ\nnew DClk=0RSDD’D’D’D\nnew D ¹old D100 -> 11\n0010 -> 010nStep-by-step analysisHowedge-triggered?\n17\nQ\nnew DClk=0RSDD’D’D’D\nQ\nDClk=¯RSDD’D’D’D0011\nRight after the clock goes from 1 to 0, the second top and second bottom NOR gates are open to the D input. As soon as the input is latched to the Q, either of these NOR gates will be 1, which blocks the new input from entering.One of two gates is 1positive edge-triggered FFnegative edge-triggered FFDCLKQposQpos’QnegQneg’100Edge-triggered D flip-flops (cont’d)nPositive edge-triggeredqinputs sampled on rising edge; outputs change after rising edgenNegative edge-triggered flip-flopsqinputs sampled on falling edge; outputs change after falling edge\nThere are two kinds of flip-flops which are triggered by the two edges of the signals: rising edge and falling edge. The previous slide shows a negative edge-triggered FF. If we add an inverter to the clock, that FF is turned into a positive edge-triggered FF. Typically, latches are level triggered and simpler. FFs are mostly edge triggered and more complicated.1819behavior is the same unless input changeswhile the clock is highDQCLKpositiveedge-triggeredflip-flopDQCCLKtransparent(level-sensitive)latchDCLKQedgeQlatchComparison of latches and flip-flops (FFs)\nAgain, in FFs, the data value only at the rising edge (or falling edge) is critical (see blue dots). Meanwhile, most latches are sensitive to D value changes as long as the clock is high. Typically, the clock input of a FF is depicted by a triangle.nDefinition of termsqclock: periodic event, causes state of memory element to changecan be rising edge or falling edge or high level or low levelqsetup time:minimum time before the clocking event by which theinput must be stable (Tsu)qhold time:minimum time after the clocking event until which theinput must remain stable (Th)\nLet’s go over terminologies first. We already know what is a clock. For each edge of a clock signal, there are some timing constraints. Suppose the positive edge of a clock signal triggers a circuit. Then the data input should be stable for an interval which is Tsu+Th, which are dependent on transistor circuit delay.20there is a timing \"window\" around the clocking event during which the input must remain stable and unchanged in order to be recognizedclockdatachangingstableinputclockTsuThclockdataDQTiming constraintsThis slide illustrates the timing where the rising edge of the clock signal is the reference. Tpd is the propagation delay between the rising edge of the clock (event trigger) and the change in the output. Tw should be long enough to ensure that D will change Q21all measurements are made from the clocking event (the rising edge of the clock)Typical timing specificationsnPositive edge-triggered D flip-flopqsetup and hold timesqminimum clock width (Tw)qpropagation delays (low to high, high to low, max and typical)D Clk Q T su 1.8ns T h 0.5ns T w 3.3 ns T pd3.6 ns 1.1 ns T su 1.8ns T h 0.5 ns T pd3.6 ns 1.1 ns T w 3.3 ns Verilog behavioral model of an edge-triggered D flip-flop\nnUse “posedge”attribute (built into Verilog)qposedge SIGis true at the positive edge of SIGDQ\n222374x74-like D flip-flop with preset and clear\nDQCLRPRCLR_L\nPR_LQQNAsynchronous CLR and PRWhy not Q_L?\n2425\n26Summary of latches and flip-flopsnDevelopment of D-FFqlevel-sensitive used in custom integrated circuitsncan be made with 4 gatesqedge-triggered used in programmable logic devicesqgood choice for data storage registernPreset and clear inputs are highly desirable on flip-flopsqused at start-up or to reset system to a known stateD-FFs can be either level-sensitive or edge-triggered. For maintenance purposes, preset and clear inputs are desirable for FFs, which will be discussed later. Preset inputs initialize the values in FFs. Clear inputs will reset the values of FFs to 0s.27RSRSRSDQDQDQDQOUT1OUT2OUT3OUT4CLKIN1IN2IN3IN4RS\"0\"RegistersnCollections of flip-flops with similar controls and logicqstored values somehow related (for example, form binary value)qshare clock, reset, and set linesqsimilar logic at each stagenExamplesqshift registersqcountersFrom now on, we will look at a collection of FFs. The first memory element to look at is a register.  A register is normally defined as a group of FFs with coordinated controls or shared controls. Examples of controls are clock, reset, set and so on. In this case, we can read/write 4 bits in parallel. 28DQDQDQDQINOUT1OUT2OUT3OUT4CLKShift registernHolds samples of inputqstore last 4 input values in sequenceq4-bit shift register:One of the relatively simple registers is a shift register. Here one bit is shifted (or moved to right) to the next FF at each clock tick (its positive edge). At each positive edge, the stored value will come out and move to the next element.clear sets the register contentsand output to 0s1 and s0 determine the shift functions0s1function00hold state01shift right10shift left11load new inputleft_inleft_outright_outclearright_inoutput\ninputs0s1clockUniversal shift registernHolds 4 valuesqserial or parallel inputsqserial or parallel outputsqpermits shift left or rightqshift in new values from left or right\nThe shift register in the previous slide goes only from left to right. Here we want to design a generic or multi-purpose shift register with the above functionalities. In addition, we also want to hold the current value without I/O. Overall, we need some control variables.2930Nth cellDQCLKQ[N-1](left)Q[N+1](right)Input[N]to N-1th cellto N+1th cellclears0s1new value1––0000output (hold)001output value of left FF (shift right)010output value of right FF(shift left)011input (load)Design of universal shift registernConsider one of the four flip-flopsqnew value at next clock cycle:\ns0 and s1control mux0123CLEAREach memory module (that stores 1 bit) should be able to perform 5 functions.  Note that there are multiple incoming lines and one of them should be selected. This should ring the bell. It will be convenient to use a MUX. Blue wires are about control while black wires are data paths. Here, clear, S1 and S0 are depicted by a single wire for simplicity. CLKclear, s0, s131parallel inputsparallel outputs\nserial transmissionShift register applicationnParallel-to-serial conversion for serial transmission\nOne of the popular application of the shift register is serial transmission, where information is transmitted over the medium bit-by-bit.32DQDQDQDQINOUT1OUT2OUT3OUT4CLKOUTPattern recognizernCombinational function of input samplesqin this case, recognizing the pattern 1001 on the single input signal\nAnother useful application of shift registers is bit string identification. In this case, bits are shifted from left to right. At any moment, if 4 bits are 1001, then OUTwill be true.33DQDQDQDQINOUT1OUT2OUT3OUT4CLKCountersnSequences through a fixed set of patternsqin this case, 1000, 0100, 0010, 0001qif one of the patterns is its initial state (by loading or set/reset)\nIf there are multiple patterns that areused for state representation, this register is typically referred to as a counter. Look at the shift register in the slide. Suppose there is a initialization (or preset) logic that stores 1000 in the register, which is not shown here. Then, as the clock ticks, the bits are rotating this ring. That’s why it is called a ring counter. 34ActivitynHow does this counter work? (initial value: 1000)DQDQDQDQINOUT1OUT2OUT3OUT4CLK§Counts through the sequence: 1000, 1100, 1110, 1111, 0111, 0011, 0001, 0000§Known as Mobius (or Johnson) counter35DQDQDQDQOUT1OUT2OUT3OUT4CLK\"1\"Binary counternLogic between registers (not just multiplexer)qXOR decides when bit should be toggledqalways for low-order bit,only when first bit is true for second bit,and so on\nHere is a binary counter; the rule of thumb is that if all lower bits are true, than the upper bit should be toggled. OUT4 is the MSB while OUT1 is the LSB.36ENDCBALOADCLKCLRRCOQDQCQBQA\n(1) Low order 4-bits = 1111(2) RCO goes high(3) High order 4-bits are incrementedFour-bit binary synchronous up-counternStandard component with many applicationsqpositive edge-triggered FFs w/ synchronous load and clear inputsqparallel load data from D, C, B, Aqenable inputs: must be asserted to enable countingqripple-carry out (RCO) is used for cascading countersnhigh when counter is in its highest state 1111nimplemented using an AND gate\nIf we use the binary counter in the previous slide as a basic component, we can build many complicated circuits, e.g. a wider binary counter. Here D is the MSB.Presetlogic37nStarting offset counters –use of synchronous loadqe.g., 0110, 0111, 1000, 1001,1010, 1011, 1100, 1101, 1111, 0110, . . .nEnding offset counter –comparator for ending valueqe.g., 0000, 0001, 0010, ..., 1100, 1101, 0000nCombinations of the above (start and stop value)ENDCBALOADCLKCLRRCOQDQCQBQA\"1\"\"0\"\"0\"\"0\"\"0\"\"0\"ENDCBALOADCLKCLRRCOQDQCQBQA\"1\"\"0\"\"1\"\"1\"\"0\"Offset counters\nOther examples are here; using the load input, we can control the initial value. Or by using some product term from the stored values, we can configure the ending value of the counter.38Sequential logic summarynFundamental building block of circuits with stateqlatch and flip-flopqR-S latch, R-S master/slave, D master/slave, edge-triggered D flip-flopnTiming methodologiesquse of clocksqSetup and hold times around the clock edgenBasic registersqshift registersqcounters"
    },
    {
        "document_id": "Lecture07_FSM.pdf",
        "text": "1Chapter 7.Finite state machines (FSMs)In chapter 6, we looked at counters, whosevalues are useful for representing states. Normally the number of states is finite. And a circuit or a system is modeled as a machine that makes transitions among states. The state is the main theme of this chapter. Some counters are moving among states without external inputs but FSMs usually have external inputs. So FSM is a kind of a superset.© Copyright 2004, Gaetano Borriello and Randy H. Katz2Finite State MachinesnSequential circuitsqprimitive sequential elementsqcombinational logicnModels for representing sequential circuitsqfinite-state machinesnDesign procedureqState/output diagramsqState/output tablesqnext state/output equationsnBasic sequential circuits revisitedqshift registersqcountersnHardware description languagesThese are the topics that will be discussed in this chapter. Of course the next state depends on the current state and the input values. The FSMs fallinto two categories: Moore and Mealy machines. Also we will look at how inputs are handled in sequential systems. Still registers and counters are key parts of the sequential circuits.3Abstraction of state elementsnDivide circuit into combinational logic and statenLocalize the feedback loops and make it easy to break cyclesnImplementation of storage elements leads to various forms of sequential logicCombinationalLogicStorage ElementsOutputsState OutputsState InputsInputs\nNow we are gonna break down a sequential logic system into two parts: combinational logic part and memory part (states). Multiple storage elements will be used to abstract the system states. The state, together with inputs, will determine the system operation: e.g. what is the next state, output?4Forms of sequential logicnAsynchronous sequential logic –state changes occur whenever state inputs change (elements may be simple wires or delay elements)nSynchronous sequential logic –state changes occur in lock step across all storage elements (using a periodic waveform -the clock)\nClockAsynchronous sequential logic circuits are operating without a clock, as shown on the left. The majority of sequential logic is synchronous logic circuits operating with clock signals, as illustrated on the right. With the clock signal, it is more convenient to control state transitions.In = 0In = 1In = 0In = 1100010110111001Finite state machine representationsnStates: determined by possible values in sequential storage elementsnTransitions: change of statenClock: controls when state can change by controlling storage elementsnSequential logicqsequences through a series of statesqbased on sequence of values on input signalsqclock period defines elements of sequenceNow we use 5 states to describe the system behavior. The number in the circle represents the state. The state transition is determined by the current state and the input. Sometimes, the state transition takes place without an input, e.g. just by a clock tick.56Example finite state machine diagramnCombination lock from introduction to courseq5 statesq5 self-transitionsq6 other transitions between statesq1 reset transition (from all states) to state S1\nresetS3closedclosedmux=C1equal& newnot equal& newnot equal& newnot equal& newnot newnot newnot newS1S2OPENERRclosedmux=C2equal& newclosedmux=C3equal& newopenLet’s revisit the door combination lock system briefly. In the example in chapter 1, there were 5 states. There are two kinds of transitions: self-transition, and ordinary transition.7Can any sequential system be represented with a state diagram?nShift registerqinput value shownon transition arcsqoutput values shownwithin state node1001101110111010100000011111000011100100DQDQDQINOUT1OUT2OUT3CLK\nThis state diagram shows all the possible states and transitions of a 3 bit shift register. In this case, the new state values are equal to output values. For example, when the system moves from 100 to 010, the output is 010. First of all, 3 bit will represent 8 states. And in each state, two kinds of input values are expected. 80101001100110010001011113-bit up-counterCounters are simple finite state machinesnCountersqproceed through well-defined sequence of states in response to enablenMany types of counters: binary, BCD, Gray-codeq3-bit up-counter: 000, 001, 010, 011, 100, 101, 110, 111, 000, ...q3-bit down-counter:  111, 110, 101, 100, 011, 010, 001, 000, 111, ...\nIn the case of a 3bit up counter, every clock tick will make a transition without any inputs. In this case the numbers follow binary coding; hence it is called a binary counter. How do we turn a state diagram into logic?nCounterq3 flip-flops to hold stateqlogic to compute next stateqclock signal controls when flip-flop memory can changenwait long enough for combinational logic to compute new valuendon't wait too long as that is low performanceDQDQDQOUT1OUT2OUT3CLK\"1\"This one is a 3bit binary (up) counter. Recall that when all the lower bits are true, the higher bit should be toggled at the next clock tick.99-Step Design ApproachnStep 1: State/output table or diagramnStep 2: Minimize # of states if possiblenStep 3: State variable assignmentnStep 4: Transition/output tablenStep 5: Choose a f/f typenStep 6: Excitation tablenStep 7: Excitation equationsnStep 8: Output equationsnStep 9: Draw a logic diagramExcitation/Output equationsState/Output tableState/output diagram\n10Problem StatementnDesign a synchronous state-machine with one input X and an output Z. Whenever the input sequence consists of two consecutive 0’s followed by two consecutive 1’s or vice versa, the output will be 1. Otherwise, the output will be 0.\n11Problem InterpretationnProblem statement is sometimes ambiguousqassume that input X is synchronous Synch. XMealy output ZMoore output Z110100011100110\nAsynch. XMealy output ZMoore output Z110100011100110if x is asynch\n12Mealy Machine\nnOutput are a function of P.S. and inputsnOutput associated with transitionnTend to give the fewest states necessarynCan cause problems when the inputs are asynchronous\nabXYcZ\nXYZXZ\n13Moore Machine\nnOutput are a function of P.S.nOutput associated with statenTend to have more statesnOutput change only with a state changeqdo not rely on asynchronous inputs\nadXYcZXYXb\n14Step 1: State/Output DiagramnDraw bubbles for all correct sequencesABCDEFGHI0/00/01/01/11/01/00/0•Meanings: A state is a meaningful abstraction of previous history(How many differentiated states? Infinite? What you need to remember? What you can forget?)–(A –got nothing), –(B –got 0), (C –got 00), (D –got 001), (E –got 0011)–(F –got 1), (G –got 11), (H –got 110), (I –got 1100)•In (E-got 0011), the future will not depend on 00 before 11 àE=G•Similarly,  I=C0/11/10/1\n15Step 1: State/Output DiagramnAdding other input sequences\nABCDEFGHI0/00/01/01/11/01/00/01/10/10/10/0\n1/00/0\n1/00/01/0\n16Step 1: State/Output DiagramnAnother approachqA state is understood as remembering something (previous history)qAll we have to remember is the last three inputsqEight states will be needed n(a=000, b=001, c=010, d=011, e=100, f=101, g=110, h=111)P.S.  X         N.S.  Za      0           a      0a      1           b      0b      0           c      0b      1           d      1c      0           e      0c      1           f       0d      0           g      0d      1           h      0e      0           a      0e      1           b      0f      0           c      0f      1           d      0g      0           e      1g      1           f       0h      0           g      0h      1           h      0abcdefgh0/01/00/01/10/01/00/01/00/01/00/01/00/11/00/01/017Step 2: State MinimizationnIdentify equivalent statesqSame output and next state (sometimes –use circular reasoning)qFormal minimization is beyond of scopeP.S.  X         N.S.  Za      0           a      0a      1           b      0b      0           c      0b      1           d      1c      0           e      0c      1           f       0d      0           g      0d      1           h      0e      0           a      0e      1           b      0f       0           c      0f       1           d      0g      0           e      1g      1           f       0h      0           g      0h      1           h      0equivalentequivalenta = e (got x00) «C (got 00)b (got 001) «D (got 001)c (got 010) «B (got 0)d = h (got x11) «G (got 11)f (got 101) «F (got 1)g (got 110) «H (got 110)\n18Step 3: State AssignmentnMajor effect on circuit costnPractical guidelinesq00…00 for initial stateqMinimize # of state variables that change on transitionqMaximize # of state variables that do not change in group of related statesqExploit symmetries –related states or group àone bit differenceqUse unused states well: Minimal risk or Minimal costqDecompose –into individual bits or fields such that each bit has well defined meaning w.r.t inputs and outputsqConsider using more than the minimum # of state variablesnOne-hot assignment àsmall excitation equations, good for 1-out-of-s coded output\n19State Assignment Examples\nStateNameSimplestQCQBQADecomposedQCQBQAOne-hotQ6-Q1ArbitraryQCQBQAa (got 000)b (got 001)c (got 010)d (got 011)f (got 101)g (got 110)000001010011100101000001010011101110000001000010000100001000010000100000000001011010110111Assignment\nWe will use this assignment although it is not particularly good20Step 4-6: Transition/Excitation/Output TableP.S.    QCQBQAX    N.S.       QCQBQAZ      DCDBDAa     0  0  0    0           a       0  0  0     0a     0  0  0    1           b       0  0  1     0b     0  0  1    0           c       0  1  1     0b     0  0  1    1           d       0  1  0     1c     0  1  1    0          e=a    0  0  0     0c     0  1  1    1           f        1  1  0     0d     0  1  0    0           g       1  1  1     0d     0  1  0    1          h=d    0  1  0     0e                   0           a                      0e                   1           b                      0f      1  1  0    0           c       0  1  1     0f      1  1  0    1           d       0  1  0     0g     1  1  1    0          e=a    0  0  0     1g     1  1  1    1           f        1  1  0     0h                   0           g                      0h                   1           h                      021Step 7-8: Excitation/Output Eqs.000010100010----QCQBQAX0001111000011110001111101110----QCQBQAX0001111000011110010110001000----QCQBQAX0001111000011110Minimum CostXQQXQQQDABABCC+=ABBABBQQXQQQD++=XQQXQQXQQDABABABA++=001000000001----QCQBQAX0001111000011110XQQXQQZACAB+=22Step 9: Logic DiagramnWill skipnHow much logic?q14 NANDsq3 F/Fsq1 InvertornMinimum Cost Design: Unused states assigned for “minimum cost”qRisk?\nqLittle risk –go into used statesqIf it is not acceptable, may have to change don’t care to specific states100 0      000100 1      001101 0      011101 1      010P.S. X     N.S.\n23240101001100110010001011113-bit up-counterpresent statenext state00000011100101022010011330111004410010155101110661101117711100003-bit Binary CounternTabular form of state diagramnLike a truth-table (specify output for all input combinations)nEncoding of states: easy for counters –just use value\nFor the 3-bit up counter, here is the state transition table. It’s like there are three inputs and three outputs. In this case the literals for states are the inputs for the state transition. If there are other outside inputs, those should be also written in the table.nD flip-flop for each state bitnCombinational logic based on encoding\n25Q3Q2Q1D3D2D1000001001010010011011100100101101110110111111000D1<= Q1’D2<= Q1Q2’ + Q1’Q2<= Q1 xorQ2D3<= Q1Q2Q3’ + Q1’Q3 + Q2’Q3<= (Q1Q2)Q3’ + (Q1’ + Q2’)Q3<= (Q1Q2)Q3’ + (Q1Q2)’Q3<= (Q1Q2) xorQ3Implementation\n00011101Q1Q2Q3D301101001Q1Q2Q3D211001100Q1Q2Q3D126Diagram for the 3-bit Binary Counter\nDQDQDQOUT1OUT2OUT3CLK\"1\"\n26nInput determines next state\n27InQ1Q2Q3NQ1NQ2NQ3  (= D1  D2  D3)0000000000100000100010011001010001001010100110011011101110001001001100101010110111011100110110111011101111111111D1<= InD2<= Q1D3<= Q2Back to the shift register\n1001101110111010100000010111111100000100\nDQDQDQINOUT1OUT2OUT3CLKHere is the state transition table for a 3bit shift register. In this case, there is one external input in addition to the current states. 28More complex counter examplenComplex counterqrepeats 5 states in sequenceqnot a binary number representationnStep 1: derive the state transition diagramqcount sequence: 000, 010, 011, 101, 110nStep 2: derive the state transition table from the state transition diagramPresent StateNext StateQcQbQaQcQbQa000010001–––010011011101100–––101110110000111–––note the don't care conditions that arise from the unused state codes010000110101011In this case, only five states are used out of 8 possible binary values; so three don’t care cases appear. Note that the next state literals are denoted with + symbol.nStep 3: K-maps for next state functions\n29Dc = QaDb = Qb’ + Qa’Qc’Da = QbQc’More complex counter example (cont’d)00X10XX1QaQbQcDc11X00XX1QaQbQcDb01X10XX0QaQbQcDa\nWe see K-maps for three counter variables here.30Self-starting counters (cont’d)nRe-deriving state transition table from don't care assignment\n00110011QaQbQcDc11100101QaQbQcDb01010000QaQbQcDaPresent StateNext StateQcQbQaQcQbQa000010001110010011011101100010101110110000111100010000110101011001111100\nCounters have two categories: self-starting and non self-starting.  In self-starting, even though the system starts in one of all possible states, which may not be legal, the system will eventually go to one of valid states. And then, the system will remain in the set of legitimate states. Note that there are no don’t care terms.31Self-starting countersnStart-up statesqat power-up, counter may be in an unused or invalid stateqdesigner must guarantee that it (eventually) enters a valid statenSelf-starting solutionqdesign counter so that invalid states eventually transition to a valid stateqmay limit exploitation of don't caresimplementationon previous slide010000110101011001111100010000110101011001111100The left two counters are non-self-starting since if the system is in the state not shown in the state diagram, it will not work.  Meanwhile the right one is self-starting.32Activityn2-bit up-down counter (2 inputs)qdirection: D = 0 for up, D = 1 for downqcount: C = 0  for hold, C = 1 for count\n01001110C=0D=XC=0D=X\nC=0D=XC=0D=XC=1D=0C=1D=0C=1D=0C=1D=0C=1D=1Q1Q0CDNQ1NQ000000000010000100100111101000101010101101001110010001010011010101110110111001111011111100011111033\nActivity (cont’d)Q1Q0CDD1D0000000000100001001001111010001010101011010011100100010100110101011101101110011110111111000111110D1 = C’Q1+ CDQ0’Q1’ + CDQ0Q1+ CD’Q0Q1’ + CD’Q0’Q1= C’Q1+ C(D’(Q1 ÅQ0) + D(Q1 ºQ0))D0 = CQ0’ + C’Q00    1    1    00    1    1    0 1    0    0    11    0    0    1 DQ1Q0C0    0    1    10    0    1    1 1    0    1    00    1    0    1 DQ1Q0C34Counter/shift-register modelnValues stored in registers represent the state of the circuitnCombinational logic computes:qnext statenfunction of current state and inputsqoutputsnvalues of flip-flopsInputsOutputsNext StateCurrent Statenext statelogicHere is the big picture of counter-or shift register-based sequential logic systems.  The current state and the input will decide the next state by forming a combinational logic in the oval. In the case of counters or registers, the values in the storage elements form the output. What if the state is not exactly the output?35General state machine modelnValues stored in registers represent the state of the circuitnCombinational logic computes:qnext statenfunction of current state and inputsqoutputsnfunction of current state and inputs (Mealy machine)nfunction of current state only (Moore machine)InputsOutputsNext StateCurrent Stateoutputlogicnext statelogicIf output is different from the state, there should be one more combinational logic, the upper oval. There is another important classification: depending on the combinational logic for outputs. If outputs are functions of only current state, that model is called a Moore machine. On the other hand, if outputs are also dependent on external inputs, this is called a Mealy machine (drawn by a blue arrow).36State machine model (cont’d)nStates: S1, S2, ..., SknInputs: I1, I2, ..., ImnOutputs: O1, O2, ..., OnnTransition function: Fs(Si, Ij)nOutput function: Fo(Si) or Fo(Si, Ij)InputsOutputsNext StateCurrent Stateoutputlogicnext statelogic\nClockNext StateState012345Again, the state transition time is the reference time, which is typically positive-(or negative-) edge of the clock signal depending on FF types. The clock period should be long enough to allow full propagation of input and the current state signals through combinational logic parts.37Comparison of Mealy and Moore machinesnMealy machines tend to have less statesqdifferent outputs on arcs (n2) rather than states (n)nMoore machines are safer to useqoutputs change at clock edge (always one cycle later)qin Mealy machines, input change can cause output change as soon as logic is done –a big problem when two machines are interconnected –asynchronous feedback may occur if one isn’t carefulnMealy machines react faster to inputsqreact in same cycle –don't need to wait for clockqin Moore machines, more logic may be necessary to decode state into outputs –more gate delays after clock edgeAs outputs of a Mealy machine are functions of the external inputs and the present state, the number of states may be less. Information for the next state transition is split between inputs from outside and the state. In Moore machines, outputs are dependent only on the present state, the output will change synchronously if combinational logic has no problem. In Mealy machines, external inputs can change the output anytime with combinational logic delay somewhat independently of the clock. If two machines perform the same function, Mealy machines react faster since inputs are already changing the combinational logic for output. Comparison of Mealy and Moore machines (cont’d)nMoorenMealystate feedbackinputsoutputsregcombinational logic for next statelogic foroutputs\ninputsoutputsstate feedbackregcombinational logic fornext statelogic foroutputsThis slide illustrates the three types of sequential systems. Synchronous Mealy machines solve the potential glitches and asynchronous change of outputs of Mealy machines by inserting clock-triggered memory elements.38D/1E/1B/0A/0C/0100001111\n0resetSpecifying outputs for a Moore machinenOutput is only function of stateqspecify in state bubble in state diagramqexample: sequence detector for 01 or 10currentnextresetinputstatestateoutput1––A00AB001AC000BB001BD000CE001CC000DE101DC100EB101ED1Let’s see how a Moore machine can be described. Here, X/Y is the tuple of state X and the output Y . The label in each incoming arc is the input. The output is associated with the current state. Actually, the output signal will be asserted until the system goes to the next state. This Moore machine detects whether the recent input string is 01 or 10. 39BAC0/10/00/01/11/01/0reset/0Specifying outputs for a Mealy machinenOutput is function of state and inputsqspecify output on transition arc between statesqexample: sequence detector for 01 or 10\nIn a Mealy machine, both the input and present state determine the next state. X/Y notation in each arrow means input X will generate output Y . Compare the number of states; the Mealy model has only 3 states. The problem of the Mealy machine is that we cannot be sure of the exact timing of output change, not to mention glitch.currentnextresetinputstatestateoutput1––A000AB001AC000BB001BC100CB101CC0\n4041VendingMachineFSMNDReset\nClockOpenCoinSensorReleaseMechanismExample: vending machinenRelease item after 15 cents are depositednSingle coin slot for dimes, nickelsnNo change\nNow we will see three or four implementations of the same vending machine that sells an item which costs 15 cents. We don’t need to figure out the exact mechanism of identifying dimes and nickels. Just assume that the corresponding wire will be asserted: N for nickel and D for dime. Also, for simplicity, we do not care about change.Dime: 10 cent coinNickel: 5 cent coin42Example: vending machine (cont’d)nState diagram\nsymbolic state tablepresentinputsnextoutputstateDNstateopen0¢000¢0015¢01010¢011––5¢005¢00110¢01015¢011––10¢0010¢00115¢01015¢011––15¢––15¢10¢Reset5¢NNN + D10¢D15¢[open]DHere is the simple state transition table for the vending machine. This is kind of a Moore machine since the output becomes 1 after the system moves to state 15¢. First of all, a dime and a nickel cannot be inserted at the same time, which implies don’t care terms.nUniquely encode states\n43present stateinputsnext stateoutputQ1Q0DNNQ1NQ0open0000000010101010011–––0100010011001011011–––1000100011101011011–––11––111Example: vending machine (cont’d)\nSo there are 4 states of the system (0,5,10,15¢), which requires minimum two FFs. The number of bits to represent states can be determined in many ways; we will look at two cases here. Two external inputs and one external output are already explained. This is a simple Moore machine since the output is dependent only on state.44\nD1 = Q1 + D + Q0 ND0 = Q0’ N + Q0 N’ + Q1 N + Q1 DOPEN = Q1 Q0Example: Moore implementationnMapping to logic00110111XX1X1111Q1D1Q0ND01101011XX1X0111Q1D0Q0ND00100010XX1X0010Q1OpenQ0ND\nThere are total 4 input variables for each output. OPEN seems to be the simplest logic. In this case, the external output is a function of only state variables. For simplicity, we skip the feedback parts of Q1 and Q0 wires.Q045present stateinputsnext stateoutputQ3Q2Q1Q0DND3D2D1D0open000100000100100100100100011-----001000001000101000101000011-----010000010000110000101000011-----1000--10001D0 = Q0 D’ N’D1 = Q0 N + Q1 D’ N’D2 = Q0 D + Q1 N + Q2 D’ N’D3 = Q1 D + Q2 D + Q2 N + Q3OPEN = Q3Example: vending machine (cont’d)nOne-hot encoding\nOne-hot encoding means onlyone bit is ON for each state; that is, only one state variable is set, or \"hot,\" for each state. So the number of bits to represent states is the same as the number of states. The benefit is that the next state generation function may be simple since the number of product terms for each output is typically small. In this case, we use 4 bits or FFs. 46Equivalent Mealy and Moore state diagramsnMoore machineqoutputs associated with state0¢[0]10¢[0]5¢[0]15¢[1]N’ D’ + ResetDDN\nN+DNN’ D’Reset’N’ D’N’ D’Reset0¢\n10¢5¢\n15¢(N’ D’ + Reset)/0D/0D/1N/0\nN+D/1N/0N’ D’/0Reset’/1N’ D’/0N’ D’/0Reset/0nMealy machineqoutputs associated with transitions\nThis slide shows the complete state transition diagram of the vending machine in two versions. In the Moore model, the number in [ ] is the output. Whereas, in the Mealy model, the output is associated with each arc.47Example: Mealy implementation0¢\n10¢5¢\n15¢Reset/0D/0D/1N/0\nN+D/1N/0N’ D’/0Reset’/1N’ D’/0N’ D’/0Reset/0present stateinputsnext stateoutputQ1Q0DND1D0open0000000010101010011–––0100010011001011111–––1000100011111011111–––11––111D0= Q0’N + Q0N’ + Q1N + Q1DD1= Q1 + D + Q0NOPEN= Q1Q0 + Q1N + Q1D + Q0D00100011XX1X0111Q1OpenQ0NDIn the case of a Mealy machine, the output, OPEN, is a function of state and the inputs.48Example: Mealy implementationD0= Q0’N + Q0N’ + Q1N + Q1DD1= Q1 + D + Q0NOPEN= Q1Q0 + Q1N + Q1D + Q0D\nHere is the overall implementation of the vending machine based on the Mealy model.\n49Hardware Description Languages Verilog for FSM\nABZDefine a new type of signal for use in symbolic state table\nSelected assignment statement -for multiple cases50Assigning specific codes to the states?nUse parameter or nUse constant definition\n515253Finite state machines summarynModels for representing sequential circuitsqabstraction of sequential elementsqfinite state machines and their state diagramsqinputs/outputsqMealy and Moore machinesnFinite state machine design procedureqderiving state diagramqderiving state transition tableqdetermining next state and output functionsqimplementing combinational logicnHardware description languagesWe start with simple FSMs like counters and shift registers, where states are outputs directly. We should differentiate Moore and Mealy models. With either model, we should be able to design a FSM."
    },
    {
        "document_id": "Lecture08_SeqAnalysis.pdf",
        "text": "Chapter 8.Sequential Circuit Analysisand Timing\n1Acknowledgments. Some slides and/or picture in the following are adapted from Digital Design: Principles and Practices(3rd Edition) by John F. Wakerlyand David E. Orin class slidesVariousTypesofFFsInput DNext state0011\nInput ENNext state0 at rising edge TQ1 at rising edge TQ’DQ\nENQJQKJKNext state00Q01010111Q’TQQ\nQQQNQQNQQN2Analysis of Clocked Synchronous State Machines•Begin with circuit•End with state diagram –word description•3 step approach\nXCLKOAB3Synchronized Operation With CLK\nStage 0Stage 1Stage 2QAQBExcitationsInputs XOutput O4Step 1: Excitation and Output Equations\nBAABABAAQQOQKXQJXKXJ=====,,,,•Derive Excitation and Output Equations from the schematic\n5Step 2: State/Output TableC.S.      Input         Excitation   QB QA   X        JB KB JA KA 0     0      0          0    1     1    0                     0     0      1          0    1     0    1                   0     1      0          1    0     1    0                 0     1      1          0    0     0    1                  1     0      0          0    1     1    0                 1     0      1          0    1     0    1                1     1      0          1    0     1    0                1     1      1          0    0     0    1               C.S.     Input  Output   QB QA   X      O0     0      0       0                      0     0      1       0                 0     1      0       0                0     1      1       0                  1     0      0       1                1     0      1       1               1     1      0       0               1     1      1       0               Output TableExcitation TableC.S.      Input         N.S QB QA   X        QB QA0     0      0          0    1                    0     0      1          0    0                   0     1      0          1    1                 0     1      1          0    0                  1     0      0          0    1                 1     0      1          0    0                1     1      0          1    1                1     1      1          1    0               Transition Table6Step 2: State/Output TableP.S.      Input     Output     Excitation                  N.S. QB QA   X        O          JB KB JA KA           QB QA 0     0      0          0          0    1     1    0               0     1                 0     0      1          0          0    1     0    1               0     0                 0     1      0          0          1    0     1    0               1     1                 0     1      1          0          0    0     0    1               0     0                 1     0      0          1          0    1     1    0               0     1                 1     0      1          1          0    1     0    1               0     0                1     1      0          0          1    0     1    0               1     1                1     1      1          0          0    0     0    1               1     0                abcd7Step 2: State/Output Table (Cont.)XState                     0                  1a                         b,0                a,0b                         d,0                a,0c                         b,1                a,1d                         d,0                c,0C.S.  X      O           N.S.a       0       0              ba       1       0              ab       0       0              db       1       0              ac       0       1              bc       1       1              ad       0       0              dd      1        0              c8Step 3: State Diagram•Can you tell what this machine is doing?abc/1d010101019Example\nQAQBCLKXO10100110aababdca10Timing•If this circuit is to work with a larger system, what are the timing requirements? –Timing specification\nXOMY\n11Metastability\nStable-0Stable-1Metastable\n12Metastability of a sequential logicRSQQNS R       Q          QN0 0     last Q   last QN0 1        0             11 0        1             01 1        0             0QQNSRstable-1stable-0metastable13Setup & Hold Times of Sequential Components (e.g. D-ff)DQ\nDCLK\n14Maximum CLK frequency•How fast can the circuit work? StateMemoryOutputLogicGNext-stateLogicFinputsoutputsclock signal•Assume inputs are ready at the right time CLKtclktffpdtcombtclk–(tffpd+tcomb) > tststh15Maximum CLK frequency•Timing specs for 74LS parts74LS04 (Inverter)74LS08 (AND)74LS109 (JK f/f)tpLH= 15 nstpHL= 15 nsPropagation delaytpLH= 15 nstpHL= 20 nsSetup timeHold timeMax freq.tpLH= 25 nstpHL= 40 nsN/AN/Ats= 35ns for H data ints= 25ns for L data inth= 5ns25 Mhz•Find the worst case delay path –Sum up worst case component delay, independent of transition direction H->L, L->H–109 tp->08 tp->109 tsetup: 40 + 20 + 35 = 95 ns–109 tp->04 tp->109 tsetup: 40 + 15 + 35 = 90 ns•Max fclk= 1/95ns = 10.5 Mhz 16Setup and Hold time specifications on X•tsfor XCLKX setupXExcitation tmaxdelayts for X\ntsX -> 04 -> JA: 15 ns orX -> 04 -> 08-> JB: 15 ns + 20 ns = 35 nstsfor X = 35 ns + 35 ns = 70 ns\n“thfor X” + tmindelay> thX -> 04 -> JA: 15 nsCLKXExcitation tmindelaythth for X•thfor XX -> KA: 0 ns or\nX -> KA: 0 nsX -> 04 -> 08-> JB: 15 ns + 15 ns = 25 nsthfor X = 5 nsuse min value17Propagation delay•X -> O: N/A (Applicable only for Mealy type output)•CLK -> O: –tpLH = max (tpLH ‘109 + tpLH ’08,  tpHL ‘109 + tpLH ’04 + tpLH ‘08)= max (25 ns + 15 ns, 40 ns + 15ns +  15 ns) = 70 ns –tpHL = max (tpHL ‘109 + tpHL ’08, tpLH ‘109 + tpHL ’04 + tpHL ’08)= max (40 ns + 20 ns, 25 ns + 15 ns + 20 ns) = 60 ns\n18Final timing spec for our circuit\nOur circuittpLH= 70 nstpHL= 60 nsts= 70 nsth= 5 ns10.5 MhzPropagation delaySetup timeHold timeMax freq.•This spec will be used for analyzing timing of a larger system containing our circuit as a component. \n19Quiz•What is the maximum clock frequency of the following circuit?XODQREADYDATAOUTCLKMY\n20Can you tell what this guy is doing?\n21SYSCNT\n22Bubble-to-bubble approach\n23Proper use of bubbles and naming•Name of a signal: Help understanding the circuit like meaningful variable names in C programs (READY , GO, ENABLE, REQUEST, etc)•Active High or Active Low (to take advantage of gate implementation, e.g.,  NOR is faster than OR)•Use the bubble to represent Active Low signal and its name has “_L” or “-”(e.g., READY_L or READY-)\n24Examples\nOPEN_LZERO_LCLR_LLD_LEN1EN2\nDSET_LRESET_LQActive low inputs (Async.)\nSET-RESET-JK-Q_LQQ-Active low inputs (Sync.)\n25MSI Chips(used in our 2’s complement machine)Read: 8.4, 8.5, 6.4(3rdEdition 8.4, 8.5, 5.4)2674LS163•4-bit, synchronous, parallel load, binary counter\nRCO\n10\n278 bit counter using 74LS163 ?•Cascading using RCO\n2874LS194•4-bit, parallel in, parallel out, bi-directional  shift register\nAsync.\n2974LS139•Dual 2-to-4 Decoder\n3074LS138•3 Enables, 3-to-8 Decoder\n31Applications of Decoder•Address decoder–In microcomputers, an I/O address is 8 bits so that there are 256 unique device addresses.–How to make 16 I/O ports of two I/O chips (8 ports of each) to the following I/O mapped addresses?Port 000Port 001Port 010Port 011Port 100Port 101Port 110Port 111Microcomputer A0A1A2A3A4A5A6A7ACBY0Y1Y2Y3Y4Y5Y6Y7G1G2AG2B74LS138A1A0A2I/O 10110000ENDATA [0..7]I/O 10110001I/O 10110010I/O 10110011I/O 10110100I/O 10110101I/O 10110110I/O 10110111I/O addr. mapping\nPort 000Port 001Port 010Port 011Port 100Port 101Port 110Port 111A1A0A2I/O 10111000ENDATA [0..7]I/O 10111001I/O 10111010I/O 10111011I/O 10111100I/O 10111101I/O 10111110I/O 10111111DATA[0..7]GND32Applications of Decoder•Cascading–Cascade small decoders for longer bits decoding–How to make 5-to-32 decoder (with 3 enables EN1, EN2-, EN3-)  using 74LS138 and 74LS139?\n33Applications of Decoder•Use as a DemultiplexerABY0Y1Y2Y3GChannel addressData-Data-•Use in combinational logic design•Use a 74LS138 to implement)(CBAABFEDF+=Y0Y1Y2Y3Y4Y5Y6Y7G1G2AG2B74LS138\nDEFACBACB10100010BAC0001111001F3435SYSCNT\n36Hints•Sequential Two’s complement machine–Analyze a machine that takes the 2’s complement of an 8-bit number•8 bits in, START à8 bits out, DONE –More realistic example that uses MSI chips–For PLDs, FPGAs design, we usually use functional blocks (LBB –Logic Building Block) equivalent to the counters, shift registers, decoders, etc 37General Architecture and Operation•Example: 01001010 à10110110 (2’s complement of A = 2n–A)–01001010 à11111111+1 –01001010  = 10110101 + 1 = 10110110–Write down bits from right until a 1 is encountered. Complements all bits there after•General Operation Flow–Load 8 bits into 2 ´74194 (4 bit shift right/left register)–Do a circular shift on the data, inverting bits as necessary–Finally, the 2’s complement data will appear at the output after 8 shift operationsParallel Data Out                                                 InvertQ7Q6Q5Q4Q3Q2Q1Q0InvertQ --------00  1  0  0  1  0  1  0                                                     01     0  0  1  0  0  1  0  1                                                     02     1  0  0  1  0  0  1  0                                                     1 3     1  1  0  0  1  0  0  1                                                     14     0  1  1  0  0  1  0  0                                                     15     1  0  1  1  0  0  1  0                                                     16     1  1  0  1  1  0  0  1                                                     17     0  1  1  0  1  1  0  0                                                     18     1  0  1  1  0  1  1  0                                                     138General Architecture and Operation•74LS194 (4 bit shift register) is used for loading & shifting 8 bit data•We use D f/f (with asynchronous clear) to remember from when inverting is necessary•We use 74LS163 (a synchronous 4-bit counter) to count 8 shifts •System controller control the overall operation–The system controller determines when data should be loaded, shifted or held by controlling S1 and S0–The system controller  also looks at BITFLG so as to know when to set the INVERT D f/f–The system controller also clears 74LS163 at the beginning, increments it each time a bit is shifted, and detects when 8 bits have been shifted.–Finally, the system controller asserts DONE signal 39Much larger system analysis•Analysis of the structure–More than a few f/fs in circuit –not practical to treat as a single state machine–Try directly applying the 3-step approach•How many f/fs?–Shift reg –8, Counter –4, INVERT –1, System Controller –2 –15 f/fs => 215states•Then, 3 step analysis only on system controller 40Synchronous System Structure\n•Generally 2 Parts: Data Unit & Control Unit–Data unit: process data (store, route, combine)–Control unit: starting and stopping actions, test conditions, decide what to do next–Only control unit –designed as state machine\n41Control unit (State Machine)Data unit42Decomposing State Machines•The control unit may be further partitioned–Main machine –system controller–Sub machines –counter, INVERT D f/f\n43Control unit (State Machine)Main machine\nsubmacine1submachine2Data unit44Do a 3 step analysis only on system controller\n45Control unit (State Machine)Data unitMain machine\nsubmacine1submachine24647Step 1: Excitation and Output Eqs.•Inputs? –External inputs (4): CLK, START, BITFLAG, C7 (ignore POC for simplification)–P.S. (2): Q1, Q2•Outputs?–External outputs (7): CLR_CNTR, RST_INVRT, S0, S1, ENCNTR, SET_INVRT, DONE–N.S. (2): = Excitations D1, D2\nBITFLAGQQCLKBITFLAGYCLKINVRTSETQQINVRTRSTQQCNTRCLRQQYDONEQQYYYSQQYSQYYENCNTRSTARTQQQSTARTQYDCQQCQYYD\n××=××=====+=++====+=+=+=+=++=\n121212120121230121122321221172172312\n ___Why falling edge of CLK? Can we remove CLK from SI equation? àNo1. avoid glitch on SI when transit to Y2 2. hold time on RIN (not likely the problem)48Step 2: State/Output Table•How many rows and columns? P.S.                     Inputs                            OutputsN.S.Q2 Q1   START BFLAG C7              EC CC S1 S0 RI SI DONEQ2(=D2) Q1(=D1) \n32 rows\n49Step 2: State/Output Table\nBITFLAGQQCLKBITFLAGYCLKINVRTSETQQINVRTRSTQQCNTRCLRQQYDONEQQYYYSQQYSQYYENCNTRSTARTQQQSTARTQYDCQQCQYYD\n××=××=====+=++====+=+=+=+=++=\n121212120121230121122321221172172312\n ___50P.S.                 OutputsN.S. Q2 Q1   EC CC S1 S0 RI SI DONE    Q2 Q1 Y0Y1Y3Y2•Variable entered tableStep 2: State/Output Table•Variable entered tableP.S.                 OutputsN.S. Q2 Q1   EC CC S1 S0 RI SI DONE    Q2 Q1 0     0     0    1    0    0   1   0    1           0   ST 0     1     0    0    1    1   0   0    01    1 1     1     1    0    0    1   0   0    0           1    0 1     0     1    0    0    1   0         0           C70 BITFLGCLK×Y0Y1Y3Y2\n51Step 3: State Diagram\nY0CC, RI, DONEY1S1, S0\nY3EC, S0Y2EC, S0STARTSTARTC7C7BITFLGCLKYSI××=2Quiz: Why we need Y3? Can we merge it with Y2?52ExampleShift registerStateCounterInvertXXXXXXXXXXXX11001010011001011011001011011001011011001011011011011011011011010011011000110110STARTY0Y1Y3Y2Y2Y2Y2Y2Y2Y2Y0Y0-00123456780-0000->11111110DONE53Sample Timing DiagramParallel Data In = 0100 1010Y0Y1Y3Y2Y2Y2Y2Y2Y2Y20statestartcounterCLR_CNTR/RST_INVRTS1/S0holdLDShift12345678\nEN_CNTR01010010Q0ShiftShiftShiftShiftShiftShiftShiftholdY0\n08 bits from right0\nBITFLG=Q7SET_INVRTINVRT(Q)DONE54Timing Analysis•Timing specs. for the parts we have usedChipLS00(2NAND), LS04(INV), LS10(3NAND), LS27(3NOR) LS86(2XOR)LS139 A,B -> YLS139 G -> YtpLH(ns)tpHL(ns)1530292415223832LS74 (Dff)CLR, CLK, PR->QDfmax = 25 MhztpLH25tpHL40ts20th5LS163 (Counter)CLK->QCLK->RCOENT->RCOtpLH243514tpHL273514ts20th5CLR->QA,B,C,D,ENP,ENT, LDfmax = 25 Mhz28200LS194 (Sft Register)CLR->QCLK->QS1, S0tpLH26tpHL3530ts30thL,R,A,B,C,DAllfmax = 25 Mhz20055Maximum CLK frequency•We must satisfy setup time for all f/f inputs (we will consider only D2, S0, RIN as examples) D2 setupPath1: CLKàQ2(LS74)+ BàY3(LS139)+ Y3àD2(LS10)+ D2_setup= 40+38+15+20=113ns Path2: CLKàQ2(LS74)+ LS00+ LS10+ D2_setup= 40+15+15+20=90ns Path3: CLKàCNTR_Q(LS163)+ CNTR_QàC7(LS10)+ LS00+ LS10+ D2_setup= 27+15+15+15+20=92ns S0 setupPath1: CLKàQ2,Q1(LS74)+ A,BàY(LS139)+ YàS0(LS10)+ S0_setup= 40+38+15+30=123ns RIN (=SRI: Shift Right Input)of Left ‘x194’setupPath1: CLKàQ0(LS194)+ LS86+ RIN_setup= 30+30+20=80ns Path2:CLK(falling edge)àSI (LS27,LS04)+ SIàINVQ(LS74)+ LS86+ RIN_setup= 15+15+25(40?)+30+20=105(120?)ns è½ tclk > 105(120?)ns è210(240?)nsMax clk frequency = 1/210ns = 4.8MhzIf we use the pure maximum value approach,Max clk frequency = 1/240ns = 4.2Mhz56Setup and Hold time specifications on START•tsfor START\n•thfor STARTCLKSTARTSTARTExcitation tmaxdelayts for START\ntsSTART -> D1: LS00+LS00tmaxdelay=15ns+15nsSTART setup = 30 ns + 20 ns = 50 nsCLKSTARTExcitation tmindelay“thfor START” + tmindelay> thth= 5 ns -> don’t have to hold STARTthth for START\ntmindelay=15ns+15ns57"
    }
]